# Copyright (c) 2025, sammish and contributors
# For license information, please see license.txt

import frappe
from frappe.utils import flt, nowdate, add_days, getdate, cint, now_datetime, date_diff
from frappe import _
import json
from datetime import datetime, timedelta
from collections import defaultdict
import math

# Advanced data science imports with fallbacks
try:
    import numpy as np
    import pandas as pd
    from scipy import stats
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import accuracy_score, mean_absolute_error
    from sklearn.linear_model import LinearRegression
    from sklearn.ensemble import RandomForestRegressor
    ML_LIBRARIES_AVAILABLE = True
except ImportError:
    ML_LIBRARIES_AVAILABLE = False

# Additional imports
import frappe
import json

def execute(filters=None):
    """
    AI-Powered Consolidated Predictive Insights Report
    Combines inventory and sales forecasting with advanced analytics
    """
    try:
        if not filters:
            filters = {}
        
        # Validate and clean filters
        filters = validate_and_clean_filters(filters)
        
        # Get report structure
        columns = get_consolidated_columns()
        data = get_consolidated_predictive_data(filters)
        
        # Generate advanced analytics
        chart_data = get_predictive_chart_data(filters)
        summary_data = get_ai_powered_summary(filters)
        
        return columns, data, None, chart_data, summary_data
        
    except Exception as e:
        frappe.log_error(f"AI Consolidated Predictive Insights execution error: {str(e)}")
        return get_consolidated_columns(), [], None, get_empty_chart(), get_error_summary(str(e))

def validate_and_clean_filters(filters):
    """Enhanced filter validation with intelligent defaults"""
    try:
        cleaned_filters = filters.copy() if filters else {}
        
        # Date range validation
        if not cleaned_filters.get("from_date"):
            cleaned_filters["from_date"] = add_days(nowdate(), -180)  # 6 months default
        
        if not cleaned_filters.get("to_date"):
            cleaned_filters["to_date"] = add_days(nowdate(), 30)  # 30 days future
        
        # Ensure logical date order
        if getdate(cleaned_filters["from_date"]) > getdate(cleaned_filters["to_date"]):
            cleaned_filters["from_date"], cleaned_filters["to_date"] = cleaned_filters["to_date"], cleaned_filters["from_date"]
        
        # AI/ML parameters
        if not cleaned_filters.get("confidence_threshold"):
            cleaned_filters["confidence_threshold"] = 70.0
        
        if not cleaned_filters.get("prediction_horizon"):
            cleaned_filters["prediction_horizon"] = 30
        
        # Ensure numeric types
        for numeric_field in ['confidence_threshold', 'prediction_horizon']:
            if cleaned_filters.get(numeric_field):
                cleaned_filters[numeric_field] = flt(cleaned_filters[numeric_field])
        
        return cleaned_filters
        
    except Exception as e:
        frappe.log_error(f"Filter validation error: {str(e)}")
        return {
            "from_date": add_days(nowdate(), -180),
            "to_date": add_days(nowdate(), 30),
            "confidence_threshold": 70.0,
            "prediction_horizon": 30
        }

def get_consolidated_columns():
    """Advanced column structure for consolidated predictive insights"""
    return [
        # Core Identification
        {
            "label": _("Item Code"),
            "fieldname": "item_code",
            "fieldtype": "Link",
            "options": "Item",
            "width": 300
        },
        {
            "label": _("Item Name"),
            "fieldname": "item_name",
            "fieldtype": "Data",
            "width": 300
        },
        {
            "label": _("Customer"),
            "fieldname": "customer",
            "fieldtype": "Link",
            "options": "Customer",
            "width": 200
        },
        {
            "label": _("Territory"),
            "fieldname": "territory",
            "fieldtype": "Link",
            "options": "Territory",
            "width": 150
        },
        {
            "label": _("Company"),
            "fieldname": "company",
            "fieldtype": "Link",
            "options": "Company",
            "width": 300
        },
        
        # Inventory Predictions
        {
            "label": _("Current Stock"),
            "fieldname": "current_stock",
            "fieldtype": "Float",
            "width": 120,
            "precision": 2
        },
        {
            "label": _("Predicted Demand"),
            "fieldname": "predicted_demand",
            "fieldtype": "Float",
            "width": 180,
            "precision": 2
        },
        {
            "label": _("Stock Projection"),
            "fieldname": "stock_projection",
            "fieldtype": "Float",
            "width": 140,
            "precision": 2
        },
        {
            "label": _("Reorder Point"),
            "fieldname": "reorder_point",
            "fieldtype": "Float",
            "width": 120,
            "precision": 2
        },
        
        # Sales Predictions
        {
            "label": _("Sales Forecast"),
            "fieldname": "sales_forecast",
            "fieldtype": "Float",
            "width": 130,
            "precision": 2
        },
        {
            "label": _("Revenue Potential"),
            "fieldname": "revenue_potential",
            "fieldtype": "Currency",
            "width": 150
        },
        {
            "label": _("Customer Score"),
            "fieldname": "customer_score",
            "fieldtype": "Float",
            "width": 140,
            "precision": 1
        },
        
        # AI/ML Analytics
        {
            "label": _("AI Confidence"),
            "fieldname": "ai_confidence",
            "fieldtype": "Percent",
            "width": 120
        },
        {
            "label": _("Demand Pattern"),
            "fieldname": "demand_pattern",
            "fieldtype": "Data",
            "width": 140
        },
        {
            "label": _("Risk Score"),
            "fieldname": "risk_score",
            "fieldtype": "Float",
            "width": 100,
            "precision": 2
        },
        {
            "label": _("Trend Direction"),
            "fieldname": "trend_direction",
            "fieldtype": "Data",
            "width": 140
        },
        {
            "label": _("Seasonality"),
            "fieldname": "seasonality_index",
            "fieldtype": "Float",
            "width": 110,
            "precision": 2
        },
        
        # Business Intelligence
        {
            "label": _("Market Potential"),
            "fieldname": "market_potential",
            "fieldtype": "Percent",
            "width": 150
        },
        {
            "label": _("Cross-sell Score"),
            "fieldname": "cross_sell_score",
            "fieldtype": "Float",
            "width": 150,
            "precision": 1
        },
        {
            "label": _("Churn Risk"),
            "fieldname": "churn_risk",
            "fieldtype": "Data",
            "width": 110
        },
        
        # Operational Insights
        {
            "label": _("Stock Status"),
            "fieldname": "stock_status",
            "fieldtype": "Data",
            "width": 250
        },
        {
            "label": _("Action Required"),
            "fieldname": "action_required",
            "fieldtype": "Data",
            "width": 340
        },
        {
            "label": _("Priority Level"),
            "fieldname": "priority_level",
            "fieldtype": "Data",
            "width": 110
        },
        
        # Timestamps
        {
            "label": _("Last Updated"),
            "fieldname": "last_updated",
            "fieldtype": "Datetime",
            "width": 180
        },
        {
            "label": _("Next Review"),
            "fieldname": "next_review",
            "fieldtype": "Date",
            "width": 120
        }
    ]

def get_consolidated_predictive_data(filters):
    """
    Advanced data consolidation with AI/ML analytics
    Combines inventory and sales forecasting data using UNION approach
    """
    try:
        # Check if required tables exist
        inventory_exists = frappe.db.table_exists("AI Inventory Forecast")
        sales_exists = frappe.db.table_exists("AI Sales Forecast")
        
        if not inventory_exists and not sales_exists:
            frappe.msgprint(_("Required forecast tables not found. Please ensure AI modules are installed."))
            # Return sample data for testing
            return get_sample_data()
        
        data = []
        
        # Get inventory data if table exists
        if inventory_exists:
            try:
                # Build conditions for inventory query
                inventory_conditions = ""
                if filters.get("company"):
                    inventory_conditions += " AND aif.company = %(company)s"
                if filters.get("item_group"):
                    inventory_conditions += " AND i.item_group = %(item_group)s"
                if filters.get("item_code"):
                    inventory_conditions += " AND aif.item_code = %(item_code)s"
                if filters.get("warehouse"):
                    inventory_conditions += " AND aif.warehouse = %(warehouse)s"
                
                inventory_query = f"""
                    SELECT DISTINCT
                        aif.item_code,
                        COALESCE(aif.item_name, aif.item_code) as item_name,
                        'All Customers' as customer,
                        COALESCE(aif.company, 'Default Company') as company,
                        'All Territories' as territory,
                        COALESCE(aif.current_stock, 0) as current_stock,
                        COALESCE(aif.predicted_consumption, 0) as predicted_demand,
                        0 as safety_stock,
                        COALESCE(aif.reorder_level, 0) as reorder_point,
                        7 as lead_time_days,
                        0 as sales_forecast,
                        0 as revenue_potential,
                        50.0 as customer_score,
                        COALESCE(aif.confidence_score, 70) as ai_confidence,
                        COALESCE(aif.movement_type, 'ðŸ“Š Unknown') as demand_pattern,
                        1.0 as seasonality_index,
                        60.0 as market_potential,
                        40.0 as cross_sell_score,
                        'ðŸŸ¡ Medium' as churn_risk,
                        COALESCE(aif.movement_type, 'Stable') as trend_direction,
                        COALESCE(aif.reorder_alert, 0) as alert_flag,
                        COALESCE(aif.last_forecast_date, NOW()) as last_updated,
                        aif.name as inventory_forecast_id,
                        '' as sales_forecast_id,
                        COALESCE(aif.warehouse, 'All Warehouses') as warehouse,
                        'inventory' as data_source
                    FROM `tabAI Inventory Forecast` aif
                    LEFT JOIN `tabItem` i ON i.name = aif.item_code
                    WHERE 1=1 {inventory_conditions}
                    LIMIT 100
                """
                
                query_params = get_clean_query_params(filters)
                inventory_data = frappe.db.sql(inventory_query, query_params, as_dict=True)
                data.extend(inventory_data)
                
            except Exception as e:
                frappe.log_error(f"Inventory data query failed: {str(e)}")
        
        # Get sales data if table exists
        if sales_exists:
            try:
                # Build conditions for sales query
                sales_conditions = ""
                if filters.get("company"):
                    sales_conditions += " AND asf.company = %(company)s"
                if filters.get("item_group"):
                    sales_conditions += " AND i.item_group = %(item_group)s"
                if filters.get("item_code"):
                    sales_conditions += " AND asf.item_code = %(item_code)s"
                if filters.get("customer"):
                    sales_conditions += " AND asf.customer = %(customer)s"
                if filters.get("territory"):
                    sales_conditions += " AND asf.territory = %(territory)s"
                
                sales_query = f"""
                    SELECT DISTINCT
                        asf.item_code,
                        COALESCE(asf.item_name, asf.item_code) as item_name,
                        COALESCE(asf.customer, 'All Customers') as customer,
                        COALESCE(asf.company, 'Default Company') as company,
                        COALESCE(asf.territory, 'All Territories') as territory,
                        0 as current_stock,
                        COALESCE(asf.predicted_qty, 0) as predicted_demand,
                        0 as safety_stock,
                        0 as reorder_point,
                        7 as lead_time_days,
                        COALESCE(asf.predicted_qty, 0) as sales_forecast,
                        0 as revenue_potential,
                        50.0 as customer_score,
                        COALESCE(asf.accuracy_score, 60) as ai_confidence,
                        COALESCE(asf.sales_trend, 'ðŸ“Š Unknown') as demand_pattern,
                        1.0 as seasonality_index,
                        60.0 as market_potential,
                        40.0 as cross_sell_score,
                        'ðŸŸ¡ Medium' as churn_risk,
                        COALESCE(asf.sales_trend, 'Stable') as trend_direction,
                        0 as alert_flag,
                        COALESCE(asf.last_forecast_date, NOW()) as last_updated,
                        '' as inventory_forecast_id,
                        asf.name as sales_forecast_id,
                        'All Warehouses' as warehouse,
                        'sales' as data_source
                    FROM `tabAI Sales Forecast` asf
                    LEFT JOIN `tabItem` i ON i.name = asf.item_code
                    LEFT JOIN `tabCustomer` c ON c.name = asf.customer
                    WHERE 1=1 {sales_conditions}
                    LIMIT 100
                """
                
                query_params = get_clean_query_params(filters)
                sales_data = frappe.db.sql(sales_query, query_params, as_dict=True)
                data.extend(sales_data)
                
            except Exception as e:
                frappe.log_error(f"Sales data query failed: {str(e)}")
        
        # If no data found, return sample data
        if not data:
            return get_sample_data()
        
        # Apply advanced AI/ML analytics
        enhanced_data = apply_advanced_analytics(data, filters)
        
        # Sort by priority
        enhanced_data.sort(key=lambda x: (
            -flt(x.get('ai_confidence', 0)),
            -cint(x.get('alert_flag', 0)),
            -flt(x.get('revenue_potential', 0)),
            -flt(x.get('predicted_demand', 0))
        ))
        
        return enhanced_data[:1000]  # Limit to 1000 records
        
    except Exception as e:
        frappe.log_error(f"Data retrieval error: {str(e)}")
        return get_sample_data()

def get_sample_data():
    """Return sample data for testing when no real data is available"""
    return [
        {
            'item_code': 'SAMPLE-001',
            'item_name': 'Sample Product 1',
            'customer': 'Sample Customer',
            'company': 'Default Company',
            'territory': 'All Territories',
            'current_stock': 100.0,
            'predicted_demand': 50.0,
            'sales_forecast': 45.0,
            'safety_stock': 0.0,
            'reorder_point': 25.0,
            'lead_time_days': 7,
            'minimum_order_qty': 10.0,
            'supplier_lead_time': 5,
            'revenue_potential': 5000.0,
            'customer_score': 75.0,
            'ai_confidence': 80.0,
            'demand_pattern': 'ðŸ“ˆ Steady Growth',
            'seasonality_index': 1.2,
            'market_potential': 70.0,
            'cross_sell_score': 60.0,
            'churn_risk': 'ðŸŸ¢ Low',
            'trend_direction': 'Increasing',
            'alert_flag': 0,
            'last_updated': frappe.utils.now(),
            'inventory_forecast_id': 'SAMPLE-INV-001',
            'sales_forecast_id': 'SAMPLE-SALES-001',
            'warehouse': 'Main Warehouse',
            'data_source': 'sample'
        },
        {
            'item_code': 'SAMPLE-002',
            'item_name': 'Sample Product 2',
            'customer': 'Sample Customer 2',
            'company': 'Default Company',
            'territory': 'All Territories',
            'current_stock': 25.0,
            'predicted_demand': 80.0,
            'sales_forecast': 75.0,
            'safety_stock': 0.0,
            'reorder_point': 40.0,
            'lead_time_days': 5,
            'minimum_order_qty': 20.0,
            'supplier_lead_time': 3,
            'revenue_potential': 8000.0,
            'customer_score': 90.0,
            'ai_confidence': 85.0,
            'demand_pattern': 'ðŸš€ High Growth',
            'seasonality_index': 1.5,
            'market_potential': 85.0,
            'cross_sell_score': 80.0,
            'churn_risk': 'ðŸŸ¡ Medium',
            'trend_direction': 'Increasing',
            'alert_flag': 1,
            'last_updated': frappe.utils.now(),
            'inventory_forecast_id': 'SAMPLE-INV-002',
            'sales_forecast_id': 'SAMPLE-SALES-002',
            'warehouse': 'Main Warehouse',
            'data_source': 'sample'
        },
        {
            'item_code': 'SAMPLE-003',
            'item_name': 'Sample Product 3 - Critical Stock',
            'customer': 'Sample Customer 3',
            'company': 'Default Company',
            'territory': 'All Territories',
            'current_stock': 5.0,
            'predicted_demand': 120.0,
            'sales_forecast': 100.0,
            'safety_stock': 15.0,
            'reorder_point': 50.0,
            'lead_time_days': 10,
            'minimum_order_qty': 50.0,
            'supplier_lead_time': 7,
            'revenue_potential': 12000.0,
            'customer_score': 95.0,
            'ai_confidence': 90.0,
            'demand_pattern': 'ðŸš€ High Growth',
            'seasonality_index': 1.8,
            'market_potential': 95.0,
            'cross_sell_score': 90.0,
            'churn_risk': 'ðŸ”´ High',
            'trend_direction': 'Increasing',
            'alert_flag': 1,
            'last_updated': frappe.utils.now(),
            'inventory_forecast_id': 'SAMPLE-INV-003',
            'sales_forecast_id': 'SAMPLE-SALES-003',
            'warehouse': 'Main Warehouse',
            'data_source': 'sample'
        }
    ]

def merge_forecast_data(inventory_data, sales_data):
    """Merge inventory and sales forecast data intelligently"""
    try:
        merged_dict = {}
        
        # Process inventory data first
        for inv_row in inventory_data:
            key = f"{inv_row.get('item_code')}_{inv_row.get('company', '')}"
            merged_dict[key] = inv_row.copy()
        
        # Merge sales data, combining where item_code and company match
        for sales_row in sales_data:
            key = f"{sales_row.get('item_code')}_{sales_row.get('company', '')}"
            
            if key in merged_dict:
                # Merge sales data into existing inventory record
                existing = merged_dict[key]
                
                # Keep the better metrics from each source
                existing['sales_forecast'] = max(
                    flt(existing.get('sales_forecast', 0)), 
                    flt(sales_row.get('sales_forecast', 0))
                )
                existing['revenue_potential'] = flt(sales_row.get('revenue_potential', 0))
                existing['customer_score'] = flt(sales_row.get('customer_score', 50))
                existing['customer'] = sales_row.get('customer', 'All Customers')
                
                # Use the higher confidence score
                existing['ai_confidence'] = max(
                    flt(existing.get('ai_confidence', 0)),
                    flt(sales_row.get('ai_confidence', 0))
                )
                
                # Update market intelligence from sales data
                existing['market_potential'] = flt(sales_row.get('market_potential', 60))
                existing['cross_sell_score'] = flt(sales_row.get('cross_sell_score', 40))
                existing['churn_risk'] = sales_row.get('churn_risk', 'ðŸŸ¡ Medium')
                
                # Combine alert flags
                existing['alert_flag'] = max(
                    cint(existing.get('alert_flag', 0)),
                    cint(sales_row.get('alert_flag', 0))
                )
                
                # Use more recent timestamp
                if sales_row.get('last_updated'):
                    existing_time = existing.get('last_updated')
                    sales_time = sales_row.get('last_updated')
                    if not existing_time or sales_time > existing_time:
                        existing['last_updated'] = sales_time
                
                # Mark as merged
                existing['data_source'] = 'merged'
                existing['sales_forecast_id'] = sales_row.get('sales_forecast_id', '')
                
            else:
                # Add sales-only record
                merged_dict[key] = sales_row.copy()
        
        return list(merged_dict.values())
        
    except Exception as e:
        frappe.log_error(f"Data merge error: {str(e)[:100]}")
        return []

def build_advanced_conditions(filters, table_alias="asf"):
    """Build intelligent query conditions with AI/ML parameters"""
    try:
        conditions = ""
        
        # Date range filtering - commented out to avoid date field issues
        # if filters.get("from_date") and filters.get("to_date"):
        #     conditions += f" AND DATE({table_alias}.forecast_date) BETWEEN %(from_date)s AND %(to_date)s"
        
        # Business filters
        if filters.get("company"):
            conditions += f" AND {table_alias}.company = %(company)s"
        
        if filters.get("item_group"):
            conditions += " AND i.item_group = %(item_group)s"
        
        # NEW: Item Code filter
        if filters.get("item_code"):
            conditions += f" AND {table_alias}.item_code = %(item_code)s"
        
        # AI/ML intelligent filters - use safe defaults
        if filters.get("confidence_threshold"):
            # For inventory, we'll use a simple check since confidence_score doesn't exist
            if table_alias == "aif":
                conditions += " AND 1=1"  # Skip confidence check for inventory
            else:
                conditions += f" AND COALESCE({table_alias}.accuracy_score, 0) >= %(confidence_threshold)s"
        
        if filters.get("high_priority_only"):
            conditions += f" AND {table_alias}.reorder_alert = 1"
        
        if filters.get("critical_items_only"):
            conditions += f" AND {table_alias}.movement_type = 'Critical'"
        
        return conditions
        
    except Exception as e:
        frappe.log_error(f"Conditions error: {str(e)[:50]}")
        return ""

def get_clean_query_params(filters):
    """Extract clean parameters for SQL execution"""
    clean_params = {}
    
    param_fields = [
        'from_date', 'to_date', 'company', 'territory', 'customer', 
        'warehouse', 'item_group', 'item_code', 'confidence_threshold'
    ]
    
    for field in param_fields:
        if filters.get(field) is not None:
            clean_params[field] = filters[field]
    
    return clean_params

def apply_advanced_analytics(data, filters):
    """Apply AI/ML analytics and business intelligence to the data"""
    if not data:
        return data
    
    try:
        enhanced_data = []
        
        for row in data:
            # Calculate derived metrics
            enhanced_row = calculate_advanced_metrics(row, filters)
            
            # Apply ML predictions if available
            if ML_LIBRARIES_AVAILABLE:
                enhanced_row = apply_ml_predictions(enhanced_row, data)
            
            # Calculate business intelligence scores
            enhanced_row = calculate_business_intelligence(enhanced_row)
            
            # Determine operational actions
            enhanced_row = determine_operational_actions(enhanced_row)
            
            enhanced_data.append(enhanced_row)
        
        # Apply portfolio-level analytics
        if ML_LIBRARIES_AVAILABLE and len(enhanced_data) > 5:
            enhanced_data = apply_portfolio_analytics(enhanced_data)
        
        return enhanced_data
        
    except Exception as e:
        frappe.log_error(f"Advanced analytics application failed: {str(e)}")
        return data

def calculate_advanced_metrics(row, filters):
    """Calculate advanced derived metrics for each row"""
    try:
        enhanced_row = row.copy()
        
        # Stock projection calculation - ensure we have valid numbers
        current_stock = flt(row.get('current_stock', 0))
        predicted_demand = flt(row.get('predicted_demand', 0))
        sales_forecast = flt(row.get('sales_forecast', 0))
        lead_time_days = cint(row.get('lead_time_days', 7))
        
        # Combined demand (max of inventory demand and sales forecast)
        combined_demand = max(predicted_demand, sales_forecast)
        enhanced_row['predicted_demand'] = combined_demand
        
        # Stock projection based on current trends
        daily_consumption = combined_demand / 30 if combined_demand > 0 else 0
        projected_stock = max(0, current_stock - (daily_consumption * lead_time_days))
        enhanced_row['stock_projection'] = round(projected_stock, 2)
        
        # Enhanced reorder point calculation
        safety_factor = 1.5 if row.get('churn_risk') == 'ðŸ”´ High' else 1.2
        enhanced_reorder = (daily_consumption * lead_time_days * safety_factor)
        enhanced_row['reorder_point'] = round(max(enhanced_reorder, flt(row.get('reorder_point', 0))), 2)
        
        # Risk score calculation (0-100 scale)
        confidence = flt(row.get('ai_confidence', 50))
        stock_risk = 100 if current_stock <= enhanced_reorder else max(0, 100 - (current_stock / enhanced_reorder) * 100) if enhanced_reorder > 0 else 0
        demand_risk = min(100, (combined_demand / max(current_stock, 1)) * 50)
        
        risk_score = (stock_risk * 0.4 + demand_risk * 0.3 + (100 - confidence) * 0.3)
        enhanced_row['risk_score'] = round(risk_score, 2)
        
        # IMPROVED Stock status determination with better logic
        item_code = str(row.get('item_code', 'N/A'))
        
        # If this is the specific item WR20065, let's add debug info
        if item_code == "WR20065":
            frappe.log_error(f"DEBUG WR20065: current_stock={current_stock}, enhanced_reorder={enhanced_reorder}, predicted_demand={predicted_demand}")
        
        # Robust stock status calculation
        if current_stock <= 0:
            stock_status = "ðŸ”´ Out of Stock"
        elif enhanced_reorder > 0 and current_stock <= enhanced_reorder:
            stock_status = f"ðŸŸ¡ Low Stock ({current_stock} available)"
        elif enhanced_reorder > 0 and current_stock <= enhanced_reorder * 2:
            stock_status = f"ðŸŸ¢ Normal Stock ({current_stock} available)"
        elif current_stock > 0:
            stock_status = f"ðŸ”µ Well Stocked ({current_stock} available)"
        else:
            # Fallback for any edge cases
            stock_status = f"ðŸ“Š Stock: {current_stock}"
        
        enhanced_row['stock_status'] = stock_status
        
        # Next review date
        if risk_score > 70:
            review_days = 3
        elif risk_score > 40:
            review_days = 7
        else:
            review_days = 14
        
        enhanced_row['next_review'] = add_days(nowdate(), review_days)
        
        return enhanced_row
        
    except Exception as e:
        frappe.log_error(f"Advanced metrics calculation failed for item {row.get('item_code', 'Unknown')}: {str(e)}")
        return row

def apply_ml_predictions(row, all_data):
    """Apply machine learning predictions and clustering"""
    try:
        if not ML_LIBRARIES_AVAILABLE or len(all_data) < 10:
            return row
        
        # Prepare feature matrix for ML analysis
        features = []
        for data_row in all_data:
            feature_vector = [
                flt(data_row.get('current_stock', 0)),
                flt(data_row.get('predicted_demand', 0)),
                flt(data_row.get('sales_forecast', 0)),
                flt(data_row.get('ai_confidence', 50)),
                flt(data_row.get('customer_score', 50)),
                flt(data_row.get('market_potential', 60)),
                flt(data_row.get('seasonality_index', 1.0)),
                flt(data_row.get('revenue_potential', 0)) / 1000  # Scale down
            ]
            features.append(feature_vector)
        
        # Convert to numpy array
        X = np.array(features)
        
        # Handle missing values
        X = np.nan_to_num(X, nan=0.0)
        
        # Standardize features
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # Apply K-means clustering for demand pattern analysis
        n_clusters = min(5, len(all_data) // 3)
        if n_clusters >= 2:
            kmeans = KMeans(n_clusters=n_clusters, random_state=42)
            clusters = kmeans.fit_predict(X_scaled)
            
            # Find current row index
            current_index = None
            for i, data_row in enumerate(all_data):
                if (data_row.get('item_code') == row.get('item_code') and 
                    data_row.get('customer') == row.get('customer')):
                    current_index = i
                    break
            
            if current_index is not None:
                cluster_id = clusters[current_index]
                cluster_patterns = {
                    0: "ðŸš€ High Growth",
                    1: "ðŸ“ˆ Steady Growth", 
                    2: "ðŸ“Š Stable Demand",
                    3: "ðŸ“‰ Declining",
                    4: "âš¡ Volatile"
                }
                row['demand_pattern'] = cluster_patterns.get(cluster_id, row.get('demand_pattern', 'ðŸ“Š Unknown'))
        
        return row
        
    except Exception as e:
        frappe.log_error(f"ML predictions failed: {str(e)}")
        return row

def calculate_business_intelligence(row):
    """Calculate advanced business intelligence metrics"""
    try:
        # Enhanced priority scoring
        risk_score = flt(row.get('risk_score', 50))
        revenue_potential = flt(row.get('revenue_potential', 0))
        customer_score = flt(row.get('customer_score', 50))
        ai_confidence = flt(row.get('ai_confidence', 50))
        
        # Priority calculation based on multiple factors
        revenue_factor = min(100, revenue_potential / 1000)  # Scale to 0-100
        priority_score = (
            risk_score * 0.35 +           # Risk weight
            revenue_factor * 0.25 +       # Revenue opportunity weight
            customer_score * 0.20 +       # Customer importance weight
            ai_confidence * 0.20          # Prediction confidence weight
        )
        
        # Determine priority level
        if priority_score >= 80:
            priority_level = "ðŸ”´ Critical"
        elif priority_score >= 60:
            priority_level = "ðŸŸ¡ High"
        elif priority_score >= 40:
            priority_level = "ðŸŸ¢ Medium"
        else:
            priority_level = "ðŸ”µ Low"
        
        row['priority_level'] = priority_level
        
        return row
        
    except Exception as e:
        frappe.log_error(f"Business intelligence calculation failed: {str(e)}")
        return row

def determine_operational_actions(row):
    """Determine specific operational actions required"""
    try:
        stock_status = row.get('stock_status', '')
        risk_score = flt(row.get('risk_score', 0))
        predicted_demand = flt(row.get('predicted_demand', 0))
        current_stock = flt(row.get('current_stock', 0))
        
        actions = []
        
        # Stock-based actions
        if "Out of Stock" in stock_status:
            actions.append("ðŸš¨ Emergency Restock")
        elif "Low Stock" in stock_status:
            actions.append("ðŸ“¦ Reorder Required")
        elif "Overstocked" in stock_status:
            actions.append("ðŸ“Š Review Inventory Levels")
        
        # Risk-based actions
        if risk_score > 80:
            actions.append("âš ï¸ Immediate Review")
        elif risk_score > 60:
            actions.append("ðŸ“ˆ Monitor Closely")
        
        # Demand-based actions
        if predicted_demand > current_stock * 2:
            actions.append("ðŸš€ Scale Up Production")
        elif predicted_demand > 0 and current_stock == 0:
            actions.append("ðŸ”„ Resume Supply")
        
        # Revenue opportunity actions
        revenue_potential = flt(row.get('revenue_potential', 0))
        if revenue_potential > 20000:
            actions.append("ðŸ’° High Revenue Focus")
        
        # Customer-based actions
        customer_score = flt(row.get('customer_score', 0))
        if customer_score > 80:
            actions.append("â­ VIP Customer Priority")
        
        # Default action if none identified
        if not actions:
            actions.append("ðŸ“‹ Regular Monitoring")
        
        row['action_required'] = " | ".join(actions[:2])  # Limit to top 2 actions
        
        return row
        
    except Exception as e:
        frappe.log_error(f"Operational actions determination failed: {str(e)}")
        return row

def apply_portfolio_analytics(data):
    """Apply portfolio-level analytics and optimizations"""
    try:
        if not ML_LIBRARIES_AVAILABLE:
            return data
        
        # Calculate portfolio metrics
        total_revenue_potential = sum(flt(row.get('revenue_potential', 0)) for row in data)
        total_predicted_demand = sum(flt(row.get('predicted_demand', 0)) for row in data)
        
        # ABC Analysis for inventory classification
        data_sorted = sorted(data, key=lambda x: flt(x.get('revenue_potential', 0)), reverse=True)
        
        cumulative_revenue = 0
        for i, row in enumerate(data_sorted):
            revenue = flt(row.get('revenue_potential', 0))
            cumulative_revenue += revenue
            
            cumulative_percentage = (cumulative_revenue / total_revenue_potential * 100) if total_revenue_potential > 0 else 0
            
            if cumulative_percentage <= 70:
                abc_class = "A - High Value"
            elif cumulative_percentage <= 90:
                abc_class = "B - Medium Value"
            else:
                abc_class = "C - Low Value"
            
            # Find and update the corresponding row in original data
            for j, original_row in enumerate(data):
                if (original_row.get('item_code') == row.get('item_code') and 
                    original_row.get('customer') == row.get('customer')):
                    data[j]['abc_classification'] = abc_class
                    break
        
        return data
        
    except Exception as e:
        frappe.log_error(f"Portfolio analytics failed: {str(e)}")
        return data

def get_predictive_chart_data(filters):
    """Generate advanced predictive analytics charts"""
    try:
        # Check if tables exist
        inventory_exists = frappe.db.table_exists("AI Inventory Forecast")
        sales_exists = frappe.db.table_exists("AI Sales Forecast")
        
        risk_data = []
        
        # Get inventory risk data if table exists
        if inventory_exists:
            try:
                inventory_risk = frappe.db.sql("""
                    SELECT 
                        CASE 
                            WHEN reorder_alert = 1 THEN 'High Risk'
                            WHEN COALESCE(current_stock, 0) < COALESCE(reorder_level, 0) THEN 'Medium Risk'
                            ELSE 'Low Risk'
                        END as risk_level,
                        COUNT(*) as count,
                        0 as avg_revenue,
                        SUM(COALESCE(predicted_consumption, 0)) as total_demand
                    FROM `tabAI Inventory Forecast`
                    WHERE 1=1
                    GROUP BY risk_level
                """, as_dict=True)
                risk_data.extend(inventory_risk)
            except Exception as e:
                frappe.log_error(f"Inventory chart query failed: {str(e)}")
        
        # Get sales risk data if table exists
        if sales_exists:
            try:
                sales_risk = frappe.db.sql("""
                    SELECT 
                        CASE 
                            WHEN COALESCE(accuracy_score, 0) < 60 THEN 'Medium Risk'
                            WHEN COALESCE(predicted_qty, 0) > 100 THEN 'Low Risk'
                            ELSE 'Low Risk'
                        END as risk_level,
                        COUNT(*) as count,
                        0 as avg_revenue,
                        SUM(COALESCE(predicted_qty, 0)) as total_demand
                    FROM `tabAI Sales Forecast`
                    WHERE 1=1
                    GROUP BY risk_level
                """, as_dict=True)
                risk_data.extend(sales_risk)
            except Exception as e:
                frappe.log_error(f"Sales chart query failed: {str(e)}")
        
        # If no data, return sample chart
        if not risk_data:
            return {
                "data": {
                    "labels": ["Low Risk", "Medium Risk", "High Risk"],
                    "datasets": [
                        {
                            "name": "Item Count",
                            "values": [15, 8, 3]
                        },
                        {
                            "name": "Avg Revenue (K)",
                            "values": [5.2, 3.1, 1.8]
                        }
                    ]
                },
                "type": "bar",
                "height": 400,
                "colors": ["#28a745", "#ffc107", "#dc3545"],
                "axisOptions": {
                    "xAxisMode": "tick",
                    "yAxisMode": "tick"
                },
                "barOptions": {
                    "spaceRatio": 0.3
                }
            }
        
        # Aggregate data by risk level
        risk_summary = {}
        for row in risk_data:
            risk_level = row.risk_level
            if risk_level not in risk_summary:
                risk_summary[risk_level] = {'count': 0, 'avg_revenue': 0, 'total_demand': 0}
            
            risk_summary[risk_level]['count'] += cint(row.count)
            risk_summary[risk_level]['avg_revenue'] += flt(row.avg_revenue or 0)
            risk_summary[risk_level]['total_demand'] += flt(row.total_demand or 0)
        
        labels = list(risk_summary.keys()) if risk_summary else ["No Data"]
        counts = [risk_summary[label]['count'] for label in labels] if risk_summary else [0]
        revenues = [round(risk_summary[label]['avg_revenue'] / 1000, 1) for label in labels] if risk_summary else [0]
        
        return {
            "data": {
                "labels": labels,
                "datasets": [
                    {
                        "name": "Item Count",
                        "values": counts
                    },
                    {
                        "name": "Avg Revenue (K)",
                        "values": revenues
                    }
                ]
            },
            "type": "bar",
            "height": 400,
            "colors": ["#dc3545", "#ffc107", "#28a745"],
            "axisOptions": {
                "xAxisMode": "tick",
                "yAxisMode": "tick"
            },
            "barOptions": {
                "spaceRatio": 0.3
            }
        }
        
    except Exception as e:
        frappe.log_error(f"Chart data error: {str(e)[:100]}")
        return get_empty_chart()

def get_ai_powered_summary(filters):
    """Generate AI-powered summary with advanced insights"""
    try:
        # Check if tables exist
        inventory_exists = frappe.db.table_exists("AI Inventory Forecast")
        sales_exists = frappe.db.table_exists("AI Sales Forecast")
        
        inv_s = {'total_items': 0, 'high_risk_items': 0, 'reorder_items': 0, 'total_predicted_demand': 0, 'total_current_stock': 0}
        sales_s = {'total_customers': 0, 'total_companies': 0, 'growth_opportunities': 0}
        
        # Get inventory stats if table exists
        if inventory_exists:
            try:
                inventory_stats = frappe.db.sql("""
                    SELECT 
                        COUNT(*) as total_items,
                        SUM(CASE WHEN reorder_alert = 1 THEN 1 ELSE 0 END) as high_risk_items,
                        SUM(CASE WHEN COALESCE(current_stock, 0) <= COALESCE(reorder_level, 0) THEN 1 ELSE 0 END) as reorder_items,
                        COUNT(CASE WHEN COALESCE(current_stock, 0) > 0 THEN 1 END) as high_confidence_items,
                        SUM(COALESCE(predicted_consumption, 0)) as total_predicted_demand,
                        SUM(COALESCE(current_stock, 0)) as total_current_stock
                    FROM `tabAI Inventory Forecast`
                    WHERE 1=1
                """, as_dict=True)
                
                if inventory_stats:
                    inv_s = inventory_stats[0]
            except Exception as e:
                frappe.log_error(f"Inventory summary query failed: {str(e)}")
        
        # Get sales stats if table exists
        if sales_exists:
            try:
                sales_stats = frappe.db.sql("""
                    SELECT 
                        COUNT(DISTINCT customer) as total_customers,
                        COUNT(DISTINCT company) as total_companies,
                        COUNT(CASE WHEN sales_trend = 'Increasing' THEN 1 END) as growth_opportunities,
                        COUNT(*) as high_market_potential
                    FROM `tabAI Sales Forecast`
                    WHERE 1=1
                """, as_dict=True)
                
                if sales_stats:
                    sales_s = sales_stats[0]
            except Exception as e:
                frappe.log_error(f"Sales summary query failed: {str(e)}")
        
        # Calculate derived metrics with safe defaults
        total_items = max(cint(inv_s.get('total_items', 0)), 1)
        high_risk_items = cint(inv_s.get('high_risk_items', 0))
        high_confidence_items = cint(inv_s.get('high_confidence_items', 0))
        
        risk_percentage = (high_risk_items / total_items) * 100 if total_items > 0 else 0
        confidence_percentage = (high_confidence_items / total_items) * 100 if total_items > 0 else 0
        
        # Stock coverage calculation with safety checks
        total_predicted_demand = flt(inv_s.get('total_predicted_demand', 0))
        total_current_stock = flt(inv_s.get('total_current_stock', 0))
        daily_demand = total_predicted_demand / 30 if total_predicted_demand > 0 else 1
        stock_coverage_days = total_current_stock / daily_demand if daily_demand > 0 else 30
        
        # Overall health assessment with safety checks
        health_score = (
            (100 - risk_percentage) * 0.4 +
            confidence_percentage * 0.3 +
            min(100, stock_coverage_days / 30 * 100) * 0.3
        ) if total_items > 0 else 75
        
        if health_score >= 80:
            health_status = "Excellent"
            health_indicator = "Green"
        elif health_score >= 60:
            health_status = "Good"
            health_indicator = "Blue"
        elif health_score >= 40:
            health_status = "Fair"
            health_indicator = "Orange"
        else:
            health_status = "Needs Attention"
            health_indicator = "Red"
        
        return [
            {
                "value": total_items,
                "label": "Total Items Analyzed",
                "datatype": "Int",
                "indicator": "Blue"
            },
            {
                "value": high_risk_items,
                "label": f"High Risk Items ({risk_percentage:.1f}%)",
                "datatype": "Int",
                "indicator": "Red" if risk_percentage > 30 else "Orange" if risk_percentage > 15 else "Green"
            },
            {
                "value": cint(inv_s.get('reorder_items', 0)),
                "label": "Items Needing Reorder",
                "datatype": "Int",
                "indicator": "Red" if cint(inv_s.get('reorder_items', 0)) > 0 else "Green"
            },
            {
                "value": "â‚¹0",
                "label": "Total Revenue Potential",
                "datatype": "Data",
                "indicator": "Blue"
            },
            {
                "value": "70.0%",
                "label": f"AI Confidence ({confidence_percentage:.1f}% High)",
                "datatype": "Data",
                "indicator": "Green"
            },
            {
                "value": cint(sales_s.get('growth_opportunities', 0)),
                "label": "Growth Opportunities",
                "datatype": "Int",
                "indicator": "Green"
            },
            {
                "value": f"{stock_coverage_days:.0f} days",
                "label": "Average Stock Coverage",
                "datatype": "Data",
                "indicator": "Green" if stock_coverage_days > 30 else "Orange" if stock_coverage_days > 15 else "Red"
            },
            {
                "value": health_status,
                "label": f"Portfolio Health ({health_score:.1f})",
                "datatype": "Data",
                "indicator": health_indicator
            }
        ]
        
    except Exception as e:
        frappe.log_error(f"Summary error: {str(e)[:100]}")
        return get_error_summary(str(e)[:50])

def get_empty_chart():
    """Return empty chart structure"""
    return {
        "data": {"labels": [], "datasets": []},
        "type": "bar",
        "height": 300
    }

def get_error_summary(error_msg):
    """Return error summary structure"""
    return [
        {
            "value": "Error",
            "label": f"Report Error: {error_msg[:50]}...",
            "datatype": "Data",
            "indicator": "Red"
        }
    ]

# Additional utility functions for ML and analytics

@frappe.whitelist()
def get_predictive_insights(filters=None):
    """API endpoint for real-time predictive insights"""
    try:
        if isinstance(filters, str):
            filters = json.loads(filters)
        
        columns, data, _, chart, summary = execute(filters)
        
        # Generate insights
        insights = analyze_predictive_patterns(data)
        recommendations = generate_ai_recommendations(data, insights)
        
        return {
            "insights": insights,
            "recommendations": recommendations,
            "data_count": len(data),
            "chart_data": chart,
            "summary": summary
        }
        
    except Exception as e:
        frappe.log_error(f"Predictive insights API failed: {str(e)}")
        return {"error": str(e)}

def analyze_predictive_patterns(data):
    """Analyze patterns in the predictive data"""
    if not data:
        return []
    
    insights = []
    
    try:
        # High risk pattern analysis
        high_risk_items = [d for d in data if flt(d.get('risk_score', 0)) > 70]
        if high_risk_items:
            insights.append({
                "type": "risk",
                "title": "High Risk Alert",
                "message": f"{len(high_risk_items)} items require immediate attention",
                "count": len(high_risk_items),
                "severity": "high"
            })
        
        # Revenue opportunity analysis
        high_revenue_items = [d for d in data if flt(d.get('revenue_potential', 0)) > 15000]
        if high_revenue_items:
            total_revenue = sum(flt(d.get('revenue_potential', 0)) for d in high_revenue_items)
            insights.append({
                "type": "opportunity",
                "title": "Revenue Opportunities",
                "message": f"â‚¹{total_revenue:,.0f} potential from {len(high_revenue_items)} items",
                "count": len(high_revenue_items),
                "severity": "medium"
            })
        
        # Stock optimization insights
        overstocked_items = [d for d in data if "Overstocked" in str(d.get('stock_status', ''))]
        if overstocked_items:
            insights.append({
                "type": "optimization",
                "title": "Inventory Optimization",
                "message": f"{len(overstocked_items)} items are overstocked",
                "count": len(overstocked_items),
                "severity": "low"
            })
        
        return insights
        
    except Exception as e:
        frappe.log_error(f"Pattern analysis failed: {str(e)}")
        return []

def generate_ai_recommendations(data, insights):
    """Generate AI-powered recommendations"""
    if not data:
        return []
    
    recommendations = []
    
    try:
        # Critical actions
        critical_items = [d for d in data if "Critical" in str(d.get('priority_level', ''))]
        if critical_items:
            top_critical = sorted(critical_items, key=lambda x: flt(x.get('risk_score', 0)), reverse=True)[:5]
            recommendations.append({
                "priority": "critical",
                "action": "Immediate Inventory Review",
                "description": f"Review {len(critical_items)} critical items starting with highest risk",
                "items": [item.get('item_code') for item in top_critical],
                "timeline": "Within 24 hours"
            })
        
        # Reorder recommendations
        reorder_items = [d for d in data if "Reorder" in str(d.get('action_required', ''))]
        if reorder_items:
            recommendations.append({
                "priority": "high",
                "action": "Purchase Order Creation",
                "description": f"Create purchase orders for {len(reorder_items)} items below reorder level",
                "items": [item.get('item_code') for item in reorder_items[:5]],
                "timeline": "Within 48 hours"
            })
        
        # Growth opportunities
        growth_items = [d for d in data if "High Revenue" in str(d.get('action_required', ''))]
        if growth_items:
            recommendations.append({
                "priority": "medium",
                "action": "Revenue Optimization",
                "description": f"Focus sales efforts on {len(growth_items)} high-potential items",
                "items": [item.get('item_code') for item in growth_items[:5]],
                "timeline": "This week"
            })
        
        return recommendations
        
    except Exception as e:
        frappe.log_error(f"AI recommendations generation failed: {str(e)}")
        return []

@frappe.whitelist()
def export_predictive_data(filters=None):
    """Export predictive data for external analysis"""
    try:
        if isinstance(filters, str):
            filters = json.loads(filters)
        
        columns, data, _, _, _ = execute(filters)
        
        # Prepare export data
        export_data = []
        for row in data:
            export_row = {}
            for col in columns:
                fieldname = col.get('fieldname')
                export_row[col.get('label')] = row.get(fieldname, '')
            export_data.append(export_row)
        
        return {
            "success": True,
            "data": export_data,
            "count": len(export_data),
            "timestamp": now_datetime()
        }
        
    except Exception as e:
        frappe.log_error(f"Export failed: {str(e)}")
        return {"success": False, "error": str(e)}

# Performance monitoring
def log_performance_metrics(operation, start_time, data_count=0):
    """Log performance metrics for optimization"""
    try:
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        # Log to system if operation takes too long
        if duration > 5:  # 5 seconds threshold
            frappe.log_error(
                f"Performance Alert: {operation} took {duration:.2f} seconds for {data_count} records",
                "AI Consolidated Report Performance"
            )
        
        return duration
        
    except Exception:
        return 0

# Analysis Button Functions
@frappe.whitelist()
def quick_reorder_analysis(filters=None):
    """ðŸ“¦ Quick Reorder Analysis - Identify items needing immediate reordering"""
    try:
        if isinstance(filters, str):
            filters = json.loads(filters)
        
        # Get current report data
        columns, data, _, _, _ = execute(filters)
        
        # If no data available, create sample data for demonstration
        if not data:
            data = [
                {"item_code": "ITEM-001", "item_name": "Sample Item 1", "current_stock": 5, "reorder_level": 20, "predicted_demand": 25, "urgency_score": 85, "risk_score": 80},
                {"item_code": "ITEM-002", "item_name": "Sample Item 2", "current_stock": 8, "reorder_level": 15, "predicted_demand": 18, "urgency_score": 75, "risk_score": 70},
                {"item_code": "ITEM-003", "item_name": "Sample Item 3", "current_stock": 2, "reorder_level": 10, "predicted_demand": 12, "urgency_score": 90, "risk_score": 85}
            ]
        
        # Filter items needing reorder
        reorder_items = []
        for item in data:
            current_stock = flt(item.get('current_stock', 0))
            reorder_point = flt(item.get('reorder_point', 0))
            risk_score = flt(item.get('risk_score', 0))
            
            if (current_stock <= reorder_point or 
                risk_score > 70 or 
                "Reorder" in str(item.get('action_required', ''))):
                
                # Calculate urgency score
                urgency = 100 - min(100, (current_stock / max(reorder_point, 1)) * 100)
                item['urgency_score'] = round(urgency, 1)
                item['days_to_stockout'] = max(1, current_stock / max(flt(item.get('predicted_demand', 1)) / 30, 0.1))
                
                reorder_items.append(item)
        
        # Sort by urgency
        reorder_items.sort(key=lambda x: (-flt(x.get('urgency_score', 0)), -flt(x.get('risk_score', 0))))
        
        return {
            "success": True,
            "title": "ðŸ“¦ Quick Reorder Analysis",
            "total_items": len(reorder_items),
            "critical_items": len([i for i in reorder_items if flt(i.get('urgency_score', 0)) > 80]),
            "items": [
                {
                    "item_code": item.get('item_code', 'N/A'),
                    "item_name": item.get('item_name', item.get('item_code', 'N/A')),
                    "current_stock": flt(item.get('current_stock', 0)),
                    "reorder_level": flt(item.get('reorder_level', 0)),
                    "urgency_score": flt(item.get('urgency_score', 0)),
                    "days_to_stockout": int(item.get('days_to_stockout', 30)),
                    "predicted_demand": flt(item.get('predicted_demand', 0)),
                    "action_required": f"Reorder {max(flt(item.get('reorder_level', 10)) - flt(item.get('current_stock', 0)), 10):.0f} units",
                    "status": "Critical" if flt(item.get('urgency_score', 0)) > 80 else "Urgent"
                }
                for item in reorder_items[:20]
            ],
            "recommendation": f"Found {len(reorder_items)} items requiring immediate attention. {len([i for i in reorder_items if flt(i.get('urgency_score', 0)) > 80])} are critical.",
            "summary": {
                "total_reorder_items": len(reorder_items),
                "critical_count": len([i for i in reorder_items if flt(i.get('urgency_score', 0)) > 80]),
                "urgent_count": len([i for i in reorder_items if 60 < flt(i.get('urgency_score', 0)) <= 80]),
                "average_urgency": round(sum(flt(i.get('urgency_score', 0)) for i in reorder_items) / max(len(reorder_items), 1), 1)
            }
        }
        
    except Exception as e:
        frappe.log_error(f"Quick reorder analysis failed: {str(e)}")
        return {"success": False, "error": str(e)}

@frappe.whitelist()
def revenue_opportunities(filters=None):
    """ðŸ’° Revenue Opportunities - Identify high-revenue potential items"""
    try:
        if isinstance(filters, str):
            filters = json.loads(filters)
        
        # Get current report data
        columns, data, _, _, _ = execute(filters)
        
        # If no data available, create sample data for demonstration
        if not data:
            data = [
                {"item_code": "ITEM-001", "item_name": "High Revenue Item", "revenue_potential": 25000, "market_potential": 85, "customer_score": 90, "current_stock": 15},
                {"item_code": "ITEM-002", "item_name": "Growth Opportunity", "revenue_potential": 18000, "market_potential": 75, "customer_score": 80, "current_stock": 12},
                {"item_code": "ITEM-003", "item_name": "Premium Product", "revenue_potential": 35000, "market_potential": 95, "customer_score": 85, "current_stock": 8}
            ]
        
        # Identify revenue opportunities
        opportunities = []
        for item in data:
            revenue_potential = flt(item.get('revenue_potential', 0))
            market_potential = flt(item.get('market_potential', 0))
            customer_score = flt(item.get('customer_score', 0))
            current_stock = flt(item.get('current_stock', 0))
            
            # Calculate opportunity score
            opportunity_score = (
                min(100, revenue_potential / 1000) * 0.4 +  # Revenue factor
                market_potential * 0.3 +                    # Market potential
                customer_score * 0.2 +                      # Customer importance
                min(100, current_stock / 10) * 0.1          # Stock availability
            )
            
            if opportunity_score > 60 or revenue_potential > 10000:
                item['opportunity_score'] = round(opportunity_score, 1)
                item['potential_profit'] = round(revenue_potential * 0.3, 2)  # Assuming 30% margin
                opportunities.append(item)
        
        # Sort by opportunity score
        opportunities.sort(key=lambda x: -flt(x.get('opportunity_score', 0)))
        
        total_revenue = sum(flt(item.get('revenue_potential', 0)) for item in opportunities)
        total_profit = sum(flt(item.get('potential_profit', 0)) for item in opportunities)
        
        return {
            "success": True,
            "title": "ðŸ’° Revenue Opportunities",
            "total_opportunities": len(opportunities),
            "total_revenue_potential": round(total_revenue, 2),
            "total_profit_potential": round(total_profit, 2),
            "items": [
                {
                    "item_code": item.get('item_code', 'N/A'),
                    "item_name": item.get('item_name', item.get('item_code', 'N/A')),
                    "revenue_potential": flt(item.get('revenue_potential', 0)),
                    "potential_profit": flt(item.get('potential_profit', 0)),
                    "opportunity_score": flt(item.get('opportunity_score', 0)),
                    "market_potential": flt(item.get('market_potential', 0)),
                    "customer_score": flt(item.get('customer_score', 0)),
                    "current_stock": flt(item.get('current_stock', 0)),
                    "action_required": f"Focus on sales - potential â‚¹{flt(item.get('revenue_potential', 0)):,.0f}",
                    "status": "High Opportunity" if flt(item.get('opportunity_score', 0)) > 80 else "Good Opportunity"
                }
                for item in opportunities[:15]
            ],
            "recommendation": f"Identified {len(opportunities)} revenue opportunities worth â‚¹{total_revenue:,.0f} with potential profit of â‚¹{total_profit:,.0f}",
            "summary": {
                "high_value_items": len([i for i in opportunities if flt(i.get('revenue_potential', 0)) > 20000]),
                "total_potential_revenue": round(total_revenue, 2),
                "total_potential_profit": round(total_profit, 2),
                "average_opportunity_score": round(sum(flt(i.get('opportunity_score', 0)) for i in opportunities) / max(len(opportunities), 1), 1)
            }
        }
        
    except Exception as e:
        frappe.log_error(f"Revenue opportunities analysis failed: {str(e)}")
        return {"success": False, "error": str(e)}

@frappe.whitelist()
def risk_assessment(filters=None):
    """âš ï¸ Risk Assessment - Comprehensive risk analysis"""
    try:
        if isinstance(filters, str):
            filters = json.loads(filters)
        
        # Get current report data
        columns, data, _, _, _ = execute(filters)
        
        # If no data available, create sample data for demonstration
        if not data:
            data = [
                {"item_code": "ITEM-001", "item_name": "High Risk Item", "risk_score": 85, "current_stock": 2, "predicted_demand": 20, "customer_score": 25, "market_potential": 30},
                {"item_code": "ITEM-002", "item_name": "Medium Risk Item", "risk_score": 65, "current_stock": 8, "predicted_demand": 15, "customer_score": 50, "market_potential": 60},
                {"item_code": "ITEM-003", "item_name": "Critical Stock", "risk_score": 95, "current_stock": 0, "predicted_demand": 25, "customer_score": 40, "market_potential": 45}
            ]
        
        # Risk analysis
        high_risk = []
        medium_risk = []
        risk_categories = {
            'stock_risk': 0,
            'demand_risk': 0,
            'customer_risk': 0,
            'market_risk': 0
        }
        
        for item in data:
            risk_score = flt(item.get('risk_score', 0))
            current_stock = flt(item.get('current_stock', 0))
            predicted_demand = flt(item.get('predicted_demand', 0))
            
            # Categorize risk levels
            if risk_score > 70:
                high_risk.append(item)
            elif risk_score > 40:
                medium_risk.append(item)
            
            # Categorize risk types
            if current_stock <= 0:
                risk_categories['stock_risk'] += 1
            if predicted_demand > current_stock * 2:
                risk_categories['demand_risk'] += 1
            if flt(item.get('customer_score', 0)) < 30:
                risk_categories['customer_risk'] += 1
            if flt(item.get('market_potential', 0)) < 40:
                risk_categories['market_risk'] += 1
        
        # Sort by risk score
        high_risk.sort(key=lambda x: -flt(x.get('risk_score', 0)))
        medium_risk.sort(key=lambda x: -flt(x.get('risk_score', 0)))
        
        total_at_risk = len(high_risk) + len(medium_risk)
        risk_percentage = (total_at_risk / max(len(data), 1)) * 100
        
        return {
            "success": True,
            "title": "âš ï¸ Risk Assessment",
            "high_risk_count": len(high_risk),
            "medium_risk_count": len(medium_risk),
            "total_at_risk": total_at_risk,
            "risk_percentage": round(risk_percentage, 1),
            "risk_categories": risk_categories,
            "items": [
                {
                    "item_code": item.get('item_code', 'N/A'),
                    "item_name": item.get('item_name', item.get('item_code', 'N/A')),
                    "risk_score": flt(item.get('risk_score', 0)),
                    "current_stock": flt(item.get('current_stock', 0)),
                    "predicted_demand": flt(item.get('predicted_demand', 0)),
                    "customer_score": flt(item.get('customer_score', 0)),
                    "market_potential": flt(item.get('market_potential', 0)),
                    "stock_risk": "High" if flt(item.get('current_stock', 0)) == 0 else "Medium" if flt(item.get('current_stock', 0)) < flt(item.get('reorder_level', 0)) else "Low",
                    "demand_risk": "High" if flt(item.get('predicted_demand', 0)) > flt(item.get('current_stock', 0)) * 2 else "Medium" if flt(item.get('predicted_demand', 0)) > flt(item.get('current_stock', 0)) else "Low",
                    "action_required": f"Risk Level: {flt(item.get('risk_score', 0)):.1f}% - {'Immediate action' if flt(item.get('risk_score', 0)) > 70 else 'Monitor closely'}",
                    "status": "High Risk" if flt(item.get('risk_score', 0)) > 70 else "Medium Risk"
                }
                for item in (high_risk[:10] + medium_risk[:10])
            ],
            "recommendation": f"Found {len(high_risk)} high-risk and {len(medium_risk)} medium-risk items ({risk_percentage:.1f}% of portfolio at risk). Immediate action required for high-risk items.",
            "summary": {
                "total_high_risk": len(high_risk),
                "total_medium_risk": len(medium_risk),
                "risk_percentage": round(risk_percentage, 1),
                "risk_breakdown": risk_categories,
                "most_critical": high_risk[0].get('item_code', 'N/A') if high_risk else 'None'
            }
        }
        
    except Exception as e:
        frappe.log_error(f"Risk assessment failed: {str(e)}")
        return {"success": False, "error": str(e)}

@frappe.whitelist()
def demand_forecasting(filters=None):
    """ðŸ“ˆ Demand Forecasting - Advanced demand analysis and predictions"""
    try:
        if isinstance(filters, str):
            filters = json.loads(filters)
        
        # Get current report data
        columns, data, _, _, _ = execute(filters)
        
        # If no data available, create sample data for demonstration
        if not data:
            data = [
                {"item_code": "ITEM-001", "item_name": "Growing Demand Item", "predicted_demand": 45, "current_stock": 20, "trend_direction": "Increasing", "seasonality_index": 1.3, "demand_pattern": "Growth", "accuracy_score": 85},
                {"item_code": "ITEM-002", "item_name": "Declining Item", "predicted_demand": 12, "current_stock": 25, "trend_direction": "Declining", "seasonality_index": 0.7, "demand_pattern": "Decline", "accuracy_score": 78},
                {"item_code": "ITEM-003", "item_name": "Seasonal Item", "predicted_demand": 35, "current_stock": 15, "trend_direction": "Stable", "seasonality_index": 1.8, "demand_pattern": "Seasonal", "accuracy_score": 82}
            ]
        
        # Demand analysis
        forecast_analysis = {
            'growing_demand': [],
            'declining_demand': [],
            'stable_demand': [],
            'volatile_demand': []
        }
        
        total_predicted_demand = 0
        seasonal_items = []
        
        for item in data:
            predicted_demand = flt(item.get('predicted_demand', 0))
            trend_direction = item.get('trend_direction', 'Stable')
            seasonality = flt(item.get('seasonality_index', 1.0))
            
            total_predicted_demand += predicted_demand
            
            # Categorize by trend
            if 'Increasing' in trend_direction or 'Growth' in str(item.get('demand_pattern', '')):
                forecast_analysis['growing_demand'].append(item)
            elif 'Declining' in trend_direction:
                forecast_analysis['declining_demand'].append(item)
            elif 'Volatile' in str(item.get('demand_pattern', '')):
                forecast_analysis['volatile_demand'].append(item)
            else:
                forecast_analysis['stable_demand'].append(item)
            
            # Identify seasonal items
            if seasonality > 1.2 or seasonality < 0.8:
                item['seasonality_impact'] = "High" if abs(seasonality - 1.0) > 0.3 else "Medium"
                seasonal_items.append(item)
        
        # Calculate demand insights
        growth_rate = len(forecast_analysis['growing_demand']) / max(len(data), 1) * 100
        decline_rate = len(forecast_analysis['declining_demand']) / max(len(data), 1) * 100
        
        return {
            "success": True,
            "title": "ðŸ“ˆ Demand Forecasting",
            "total_predicted_demand": round(total_predicted_demand, 2),
            "growth_rate": round(growth_rate, 1),
            "decline_rate": round(decline_rate, 1),
            "growing_items": len(forecast_analysis['growing_demand']),
            "declining_items": len(forecast_analysis['declining_demand']),
            "stable_items": len(forecast_analysis['stable_demand']),
            "volatile_items": len(forecast_analysis['volatile_demand']),
            "seasonal_items": len(seasonal_items),
            "items": [
                {
                    "item_code": item.get('item_code', 'N/A'),
                    "item_name": item.get('item_name', item.get('item_code', 'N/A')),
                    "predicted_demand": flt(item.get('predicted_demand', 0)),
                    "current_stock": flt(item.get('current_stock', 0)),
                    "trend_direction": item.get('trend_direction', 'Stable'),
                    "seasonality_index": flt(item.get('seasonality_index', 1.0)),
                    "demand_pattern": item.get('demand_pattern', 'Normal'),
                    "forecast_confidence": flt(item.get('accuracy_score', 70)),
                    "action_required": f"Expected demand: {flt(item.get('predicted_demand', 0)):.0f} units - {item.get('trend_direction', 'Stable')} trend",
                    "status": "Growing" if 'Increasing' in str(item.get('trend_direction', '')) else "Declining" if 'Declining' in str(item.get('trend_direction', '')) else "Stable",
                    "category": "Growing" if item in forecast_analysis['growing_demand'] else "Declining" if item in forecast_analysis['declining_demand'] else "Volatile" if item in forecast_analysis['volatile_demand'] else "Stable"
                }
                for item in (forecast_analysis['growing_demand'][:8] + forecast_analysis['declining_demand'][:6] + seasonal_items[:6])
            ],
            "recommendation": f"Portfolio shows {growth_rate:.1f}% growth trend with {len(seasonal_items)} seasonal items requiring special attention",
            "summary": {
                "total_predicted_demand": round(total_predicted_demand, 2),
                "growth_percentage": round(growth_rate, 1),
                "decline_percentage": round(decline_rate, 1),
                "forecast_breakdown": {
                    "growing": len(forecast_analysis['growing_demand']),
                    "declining": len(forecast_analysis['declining_demand']),
                    "stable": len(forecast_analysis['stable_demand']),
                    "volatile": len(forecast_analysis['volatile_demand'])
                },
                "seasonal_impact": len(seasonal_items)
            }
        }
        
    except Exception as e:
        frappe.log_error(f"Demand forecasting analysis failed: {str(e)}")
        return {"success": False, "error": str(e)}

@frappe.whitelist()
def create_ai_purchase_order(items_data=None, filters=None):
    """ðŸ›’ AI Purchase Order - Intelligent purchase order creation"""
    try:
        if isinstance(items_data, str):
            items_data = json.loads(items_data)
        if isinstance(filters, str):
            filters = json.loads(filters)
        
        # If no specific items provided, get reorder items from analysis
        if not items_data:
            reorder_result = perform_quick_reorder_analysis(filters)
            if reorder_result.get('success'):
                # Get the actual item lists from the analysis result
                critical_items_list = reorder_result.get('critical_items', [])
                reorder_items_list = reorder_result.get('reorder_items', [])
                
                # Ensure we have lists, not other data types
                if isinstance(critical_items_list, list):
                    items_data = critical_items_list[:5]  # Top 5 critical items
                else:
                    items_data = []
                
                if isinstance(reorder_items_list, list):
                    items_data.extend(reorder_items_list[:10])  # Add top 10 reorder items
                
                # If still no items, try to get from quick_reorder_analysis function directly
                if not items_data:
                    quick_result = quick_reorder_analysis(filters)
                    if quick_result.get('success') and quick_result.get('items'):
                        items_data = quick_result.get('items', [])[:15]  # Top 15 items
            else:
                # If no analysis data, create sample items for demo
                items_data = create_sample_po_items()
        
        if not items_data:
            frappe.log_error("No items_data found for purchase order creation")
            return {"success": False, "error": "No items found for purchase order creation"}
        
        # Validate items_data structure
        if not isinstance(items_data, list):
            frappe.log_error(f"items_data is not a list: {type(items_data)}, value: {items_data}")
            return {"success": False, "error": "Invalid items data format"}
        
        frappe.log_error(f"Processing {len(items_data)} items for purchase order creation")
        
        # Ensure default supplier exists
        supplier_name = ensure_default_supplier()
        
        # Create the actual Purchase Order document
        po_doc = frappe.new_doc("Purchase Order")
        po_doc.supplier = supplier_name
        po_doc.company = frappe.defaults.get_user_default("Company") or frappe.db.get_single_value("Global Defaults", "default_company") or "AI Inventory"
        po_doc.transaction_date = frappe.utils.nowdate()
        po_doc.schedule_date = frappe.utils.add_days(frappe.utils.nowdate(), 7)  # 7 days from now
        
        # Add a note about AI generation
        po_doc.remarks = "This Purchase Order was automatically generated by AI Analytics based on stock analysis and demand forecasting."
        
        total_amount = 0
        po_items_details = []
        
        for item in items_data:
            try:
                # Ensure item is a dictionary
                if not isinstance(item, dict):
                    frappe.log_error(f"Item is not a dictionary: {type(item)}, value: {item}")
                    continue
                
                item_code = item.get('item_code')
                if not item_code:
                    frappe.log_error(f"Item missing item_code: {item}")
                    continue
                    
                # Check if item exists
                if not frappe.db.exists("Item", item_code):
                    frappe.log_error(f"Item {item_code} does not exist, skipping...")
                    continue
                
                current_stock = flt(item.get('current_stock', 0))
                reorder_level = flt(item.get('reorder_level', 10))
                predicted_demand = flt(item.get('predicted_demand', 20))
                suggested_qty = flt(item.get('suggested_qty', 0))
                
                # Calculate order quantity if not provided
                if suggested_qty <= 0:
                    monthly_demand = predicted_demand if predicted_demand > 0 else 20
                    order_qty = max(monthly_demand, reorder_level - current_stock, 10)
                else:
                    order_qty = suggested_qty
                
                # Ensure quantity is a whole number to avoid UOM errors
                order_qty = max(int(round(order_qty)), 1)
                
                if order_qty > 0:
                    # Get item details
                    item_doc = frappe.get_doc("Item", item_code)
                    
                    # Ensure UOM allows fractional quantities or use Nos
                    stock_uom = item_doc.stock_uom or "Nos"
                    
                    # Try to get UOM settings and ensure it allows whole numbers
                    try:
                        uom_doc = frappe.get_doc("UOM", stock_uom)
                        # If UOM must be whole number, ensure our quantity is integer
                        if getattr(uom_doc, 'must_be_whole_number', 0):
                            order_qty = max(int(round(order_qty)), 1)
                    except:
                        # If UOM doesn't exist or error, default to Nos
                        stock_uom = "Nos"
                        order_qty = max(int(round(order_qty)), 1)
                    
                    # Try to get rate from item master or use default
                    rate = item_doc.standard_rate or item_doc.valuation_rate or 100.0
                    
                    # Get default warehouse
                    default_warehouse = frappe.db.get_single_value("Stock Settings", "default_warehouse")
                    if not default_warehouse:
                        # Try to get any warehouse
                        warehouse_list = frappe.db.sql("SELECT name FROM tabWarehouse LIMIT 1", as_dict=True)
                        default_warehouse = warehouse_list[0].name if warehouse_list else "Main Warehouse"
                
                # Add item to Purchase Order
                po_item = po_doc.append("items", {
                    "item_code": item_code,
                    "item_name": item_doc.item_name,
                    "description": item_doc.description or item_doc.item_name,
                    "qty": int(order_qty),  # Ensure integer quantity
                    "rate": rate,
                    "amount": int(order_qty) * rate,
                    "uom": stock_uom,  # Use the validated UOM
                    "schedule_date": po_doc.schedule_date,
                    "warehouse": default_warehouse
                })
                
                total_amount += int(order_qty) * rate
                
                # Store details for response
                po_items_details.append({
                    'item_code': item_code,
                    'item_name': item_doc.item_name,
                    'qty': int(order_qty),  # Ensure integer quantity in response
                    'rate': rate,
                    'amount': int(order_qty) * rate,
                    'urgency_score': item.get('urgency_score', 50),
                    'current_stock': current_stock,
                    'stock_status': item.get('stock_status', 'Review Required')
                })
                
            except Exception as item_error:
                frappe.log_error(f"Failed to process item: {str(item_error)}")
                continue
        
        if not po_doc.items:
            return {"success": False, "error": "No valid items found for purchase order creation"}
        
        # Save the document
        try:
            po_doc.insert()
            frappe.db.commit()
        except Exception as save_error:
            frappe.log_error(f"Purchase Order save failed: {str(save_error)}")
            # Try to handle common errors
            if "fraction" in str(save_error).lower() or "whole number" in str(save_error).lower():
                # Retry with all quantities as integers
                for item in po_doc.items:
                    item.qty = max(int(item.qty), 1)
                    item.amount = item.qty * item.rate
                try:
                    po_doc.save()
                    frappe.db.commit()
                except Exception as retry_error:
                    return {"success": False, "error": f"Failed to create PO even after quantity adjustment: {str(retry_error)}"}
            else:
                return {"success": False, "error": f"Failed to save Purchase Order: {str(save_error)}"}
        
        return {
            "success": True,
            "title": "ðŸ›’ AI Purchase Order Created",
            "po_number": po_doc.name,
            "supplier": po_doc.supplier,
            "total_amount": round(total_amount, 2),
            "items_count": len(po_doc.items),
            "items": po_items_details,
            "recommendation": f"Successfully created Purchase Order {po_doc.name} for {len(po_doc.items)} items worth â‚¹{total_amount:,.2f}",
            "po_link": f"/app/purchase-order/{po_doc.name}",
            "next_steps": [
                f"ðŸ“‹ Review Purchase Order: {po_doc.name}",
                "âœ… Verify supplier information and rates",
                "ðŸ“ž Contact supplier for confirmation", 
                "ðŸ’° Check budget approval if required",
                "ðŸ“… Confirm delivery schedule",
                "ðŸšš Submit and process the order"
            ],
            "insights": [
                f"ðŸ“„ Purchase Order: {po_doc.name}",
                f"ðŸ’° Total Value: â‚¹{total_amount:,.2f}",
                f"ðŸ“¦ Items: {len(po_doc.items)}",
                f"ðŸ“… Expected Delivery: {po_doc.schedule_date}",
                f"ðŸª Supplier: {po_doc.supplier}"
            ]
        }
        
    except Exception as e:
        frappe.log_error(f"AI purchase order creation failed: {str(e)}")
        return {
            "success": False, 
            "error": f"Failed to create purchase order: {str(e)}",
            "details": "Check error logs for more information"
        }

def ensure_default_supplier():
    """Ensure default supplier exists for AI purchase orders"""
    supplier_name = "AI Default Supplier"
    
    if not frappe.db.exists("Supplier", supplier_name):
        try:
            supplier_doc = frappe.new_doc("Supplier")
            supplier_doc.supplier_name = supplier_name
            supplier_doc.supplier_group = "All Supplier Groups"
            supplier_doc.insert()
            frappe.db.commit()
            frappe.logger().info(f"Created default supplier: {supplier_name}")
        except Exception as e:
            frappe.logger().error(f"Failed to create default supplier: {str(e)}")
            # Fallback to any existing supplier
            existing_suppliers = frappe.db.sql("SELECT name FROM tabSupplier LIMIT 1", as_dict=True)
            if existing_suppliers:
                supplier_name = existing_suppliers[0].name
            else:
                # Last resort - use a simple name that might work
                supplier_name = "Default Supplier"
    
    return supplier_name

def get_ai_recommended_supplier(item_code):
    """Get AI-recommended supplier for an item"""
    try:
        # First check AI Inventory Forecast for preferred supplier
        ai_supplier = frappe.db.sql("""
            SELECT preferred_supplier, confidence_score
            FROM `tabAI Inventory Forecast`
            WHERE item_code = %s AND preferred_supplier IS NOT NULL
            ORDER BY last_forecast_date DESC
            LIMIT 1
        """, (item_code,), as_dict=True)
        
        if ai_supplier and ai_supplier[0].get('preferred_supplier'):
            return {
                'supplier': ai_supplier[0]['preferred_supplier'],
                'confidence': flt(ai_supplier[0].get('confidence_score', 75)),
                'source': 'AI Recommendation'
            }
        
        # Fallback to Item Default Supplier
        default_supplier = frappe.db.sql("""
            SELECT ids.supplier, ids.supplier_name
            FROM `tabItem Default` ids
            INNER JOIN `tabItem` i ON i.name = ids.parent
            WHERE i.name = %s AND ids.company = %s
            ORDER BY ids.creation DESC
            LIMIT 1
        """, (item_code, frappe.defaults.get_user_default("Company") or ""), as_dict=True)
        
        if default_supplier:
            return {
                'supplier': default_supplier[0].get('supplier_name') or default_supplier[0]['supplier'],
                'confidence': 60,
                'source': 'Item Default'
            }
        
        # Last fallback - most recent supplier for this item
        recent_supplier = frappe.db.sql("""
            SELECT poi.supplier
            FROM `tabPurchase Order Item` poi
            INNER JOIN `tabPurchase Order` po ON po.name = poi.parent
            WHERE poi.item_code = %s AND po.docstatus = 1
            ORDER BY po.transaction_date DESC
            LIMIT 1
        """, (item_code,), as_dict=True)
        
        if recent_supplier:
            return {
                'supplier': recent_supplier[0]['supplier'],
                'confidence': 50,
                'source': 'Recent Purchase'
            }
        
        # Ultimate fallback
        return {
            'supplier': 'AI Default Supplier',
            'confidence': 30,
            'source': 'System Default'
        }
        
    except Exception as e:
        frappe.log_error(f"Failed to get AI recommended supplier for {item_code}: {str(e)}")
        return {
            'supplier': 'AI Default Supplier',
            'confidence': 30,
            'source': 'Error Fallback'
        }

def get_alternative_suppliers(item_code):
    """Get alternative suppliers for an item"""
    try:
        suppliers = frappe.db.sql("""
            SELECT DISTINCT poi.supplier, COUNT(*) as order_count,
                   AVG(poi.rate) as avg_rate,
                   MAX(po.transaction_date) as last_order_date
            FROM `tabPurchase Order Item` poi
            INNER JOIN `tabPurchase Order` po ON po.name = poi.parent
            WHERE poi.item_code = %s AND po.docstatus = 1
            GROUP BY poi.supplier
            ORDER BY order_count DESC, last_order_date DESC
            LIMIT 5
        """, (item_code,), as_dict=True)
        
        if not suppliers:
            # Get any suppliers from Item Default
            default_suppliers = frappe.db.sql("""
                SELECT ids.supplier_name as supplier, 0 as order_count,
                       0 as avg_rate, NULL as last_order_date
                FROM `tabItem Default` ids
                WHERE ids.parent = %s
                LIMIT 3
            """, (item_code,), as_dict=True)
            suppliers.extend(default_suppliers)
        
        return [{
            'supplier': supplier['supplier'],
            'order_count': supplier.get('order_count', 0),
            'avg_rate': round(flt(supplier.get('avg_rate', 0)), 2),
            'last_order': supplier.get('last_order_date'),
            'reliability': 'High' if supplier.get('order_count', 0) > 5 else 'Medium' if supplier.get('order_count', 0) > 2 else 'New'
        } for supplier in suppliers]
        
    except Exception as e:
        frappe.log_error(f"Failed to get alternative suppliers for {item_code}: {str(e)}")
        return []

def get_estimated_item_rate(item_code):
    """Get estimated rate for an item from multiple sources"""
    try:
        # First try to get from Item master
        item_rates = frappe.db.sql("""
            SELECT standard_rate, valuation_rate
            FROM `tabItem`
            WHERE name = %s
        """, (item_code,), as_dict=True)
        
        if item_rates and item_rates[0]:
            standard_rate = flt(item_rates[0].get('standard_rate', 0))
            valuation_rate = flt(item_rates[0].get('valuation_rate', 0))
            
            if standard_rate > 0:
                return standard_rate
            elif valuation_rate > 0:
                return valuation_rate
        
        # Try to get recent purchase rate
        recent_rate = frappe.db.sql("""
            SELECT poi.rate
            FROM `tabPurchase Order Item` poi
            INNER JOIN `tabPurchase Order` po ON po.name = poi.parent
            WHERE poi.item_code = %s AND po.docstatus = 1
            ORDER BY po.transaction_date DESC
            LIMIT 1
        """, (item_code,), as_dict=True)
        
        if recent_rate and recent_rate[0].get('rate'):
            return flt(recent_rate[0]['rate'])
        
        # Try to get from Price List
        price_list_rate = frappe.db.sql("""
            SELECT price_list_rate
            FROM `tabItem Price`
            WHERE item_code = %s AND selling = 0
            ORDER BY valid_from DESC
            LIMIT 1
        """, (item_code,), as_dict=True)
        
        if price_list_rate and price_list_rate[0].get('price_list_rate'):
            return flt(price_list_rate[0]['price_list_rate'])
        
        # Default fallback rate
        return 100.0
        
    except Exception as e:
        frappe.log_error(f"Failed to get estimated rate for {item_code}: {str(e)}")
        return 100.0

def determine_stock_status(current_stock, reorder_level, predicted_demand):
    """Determine detailed stock status with enhanced logic"""
    try:
        current_stock = flt(current_stock)
        reorder_level = flt(reorder_level)
        predicted_demand = flt(predicted_demand)
        
        if current_stock <= 0:
            return "ðŸ”´ Out of Stock - Critical"
        elif current_stock <= reorder_level * 0.5:
            return f"ðŸŸ¡ Very Low Stock ({current_stock} units)"
        elif current_stock <= reorder_level:
            return f"ðŸŸ  Below Reorder Level ({current_stock} units)"
        elif predicted_demand > 0 and current_stock <= predicted_demand * 0.5:
            return f"ðŸŸ¡ Low for Demand ({current_stock} vs {predicted_demand:.0f} needed)"
        elif current_stock <= reorder_level * 1.5:
            return f"ðŸŸ¢ Approaching Reorder ({current_stock} units)"
        else:
            return f"ðŸ”µ Adequate Stock ({current_stock} units)"
    except:
        return f"ðŸ“Š Stock: {current_stock}"

def calculate_days_stock_remaining(current_stock, predicted_demand):
    """Calculate days of stock remaining"""
    try:
        current_stock = flt(current_stock)
        predicted_demand = flt(predicted_demand)
        
        if predicted_demand <= 0:
            return 999  # Infinite if no demand
        
        daily_demand = predicted_demand / 30  # Convert monthly to daily
        if daily_demand <= 0:
            return 999
        
        days_remaining = current_stock / daily_demand
        return max(0, round(days_remaining, 1))
    except:
        return 0

def analyze_supplier_distribution(items):
    """Analyze supplier distribution across items"""
    try:
        supplier_count = {}
        total_amount = 0
        
        for item in items:
            supplier = item.get('ai_supplier', 'Unknown')
            amount = flt(item.get('amount', 0))
            
            if supplier in supplier_count:
                supplier_count[supplier]['count'] += 1
                supplier_count[supplier]['amount'] += amount
            else:
                supplier_count[supplier] = {'count': 1, 'amount': amount}
            
            total_amount += amount
        
        # Find primary supplier (highest count or amount)
        primary_supplier = 'Multiple Suppliers'
        if supplier_count:
            primary = max(supplier_count.items(), key=lambda x: (x[1]['count'], x[1]['amount']))
            primary_supplier = primary[0]
        
        # Calculate distribution percentages
        distribution = {}
        for supplier, data in supplier_count.items():
            distribution[supplier] = {
                'items': data['count'],
                'amount': round(data['amount'], 2),
                'percentage': round((data['amount'] / max(total_amount, 1)) * 100, 1)
            }
        
        return {
            'primary_supplier': primary_supplier,
            'distribution': distribution,
            'total_suppliers': len(supplier_count),
            'total_amount': round(total_amount, 2)
        }
        
    except Exception as e:
        frappe.log_error(f"Failed to analyze supplier distribution: {str(e)}")
        return {
            'primary_supplier': 'AI Default Supplier',
            'distribution': {},
            'total_suppliers': 1,
            'total_amount': 0
        }

def get_all_supplier_options():
    """Get all available suppliers for dropdown selection"""
    try:
        suppliers = frappe.db.sql("""
            SELECT name as supplier_name, supplier_group,
                   (SELECT COUNT(*) FROM `tabPurchase Order` po 
                    WHERE po.supplier = s.name AND po.docstatus = 1) as order_count
            FROM `tabSupplier` s
            WHERE s.disabled = 0
            ORDER BY order_count DESC, s.name
            LIMIT 20
        """, as_dict=True)
        
        return [{
            'supplier_name': supplier['supplier_name'],
            'supplier_group': supplier.get('supplier_group', 'All Supplier Groups'),
            'order_count': supplier.get('order_count', 0),
            'reliability': 'High' if supplier.get('order_count', 0) > 10 else 'Medium' if supplier.get('order_count', 0) > 3 else 'New'
        } for supplier in suppliers]
        
    except Exception as e:
        frappe.log_error(f"Failed to get supplier options: {str(e)}")
        return [{'supplier_name': 'AI Default Supplier', 'supplier_group': 'Default', 'order_count': 0, 'reliability': 'New'}]

@frappe.whitelist()
def ai_purchase_order(filters=None):
    """ðŸ›’ AI Purchase Order - Main entry point for AI-powered purchase order analysis"""
    return create_ai_purchase_order(None, filters)

@frappe.whitelist()
def preview_ai_purchase_order(filters=None):
    """ðŸ›’ AI Purchase Order Preview - Enhanced preview with validation and supplier selection"""
    try:
        if isinstance(filters, str):
            filters = json.loads(filters)
        
        # Get consolidated data for analysis
        data = get_consolidated_predictive_data(filters or {})
        
        if not data:
            return {
                "success": False,
                "error": "No valid items found for purchase order creation",
                "validation_message": "No items require purchase at this time based on forecast and stock levels. All items appear to have adequate stock or no demand forecast.",
                "suggestions": [
                    "Check if forecast data is up to date",
                    "Review stock levels manually",
                    "Adjust reorder levels if needed",
                    "Wait for new demand forecasts"
                ]
            }
        
        # Enhanced analysis for items needing reorder
        preview_items = []
        total_items_analyzed = len(data)
        
        for row in data:
            current_stock = flt(row.get('current_stock', 0))
            predicted_demand = flt(row.get('predicted_demand', 0))
            reorder_level = flt(row.get('reorder_level', 0))
            risk_score = flt(row.get('risk_score', 0))
            
            # Enhanced criteria for reorder necessity
            needs_reorder = False
            urgency_score = 0
            reorder_reason = []
            
            # Check multiple conditions
            if current_stock <= 0:
                needs_reorder = True
                urgency_score += 50
                reorder_reason.append("Out of stock")
            elif current_stock <= reorder_level:
                needs_reorder = True
                urgency_score += 30
                reorder_reason.append("Below reorder level")
            elif predicted_demand > current_stock:
                needs_reorder = True
                urgency_score += 25
                reorder_reason.append("Predicted demand exceeds stock")
            elif risk_score > 70:
                needs_reorder = True
                urgency_score += 20
                reorder_reason.append("High risk score")
            
            if needs_reorder:
                # Calculate suggested quantity with better logic
                safety_buffer = max(reorder_level * 0.2, 5)  # 20% buffer or minimum 5 units
                
                if current_stock <= 0:
                    suggested_qty = max(predicted_demand, reorder_level, 10)
                elif current_stock <= reorder_level:
                    suggested_qty = max(reorder_level - current_stock + safety_buffer, predicted_demand * 0.5, 5)
                else:
                    suggested_qty = max(predicted_demand - current_stock + safety_buffer, 5)
                
                suggested_qty = max(int(suggested_qty), 1)
                
                # Get AI-selected supplier or fallback to item default
                ai_supplier = get_ai_recommended_supplier(row.get('item_code'))
                
                # Get estimated rate from multiple sources
                estimated_rate = get_estimated_item_rate(row.get('item_code'))
                
                preview_items.append({
                    'item_code': row.get('item_code'),
                    'item_name': row.get('item_name', row.get('item_code')),
                    'current_stock': current_stock,
                    'reorder_level': reorder_level,
                    'predicted_demand': predicted_demand,
                    'suggested_qty': suggested_qty,
                    'rate': estimated_rate,
                    'amount': suggested_qty * estimated_rate,
                    'urgency_score': min(100, urgency_score),
                    'reorder_reason': " | ".join(reorder_reason),
                    'ai_supplier': ai_supplier.get('supplier'),
                    'supplier_confidence': ai_supplier.get('confidence', 70),
                    'alternative_suppliers': get_alternative_suppliers(row.get('item_code')),
                    'stock_status': determine_stock_status(current_stock, reorder_level, predicted_demand),
                    'days_stock_remaining': calculate_days_stock_remaining(current_stock, predicted_demand)
                })
        
        # Sort by urgency score (highest first)
        preview_items.sort(key=lambda x: (-x['urgency_score'], -x['predicted_demand']))
        
        # Limit to top 20 items for better UX
        preview_items = preview_items[:20]
        
        if not preview_items:
            return {
                "success": False,
                "error": "No items require purchase order creation",
                "validation_message": f"After analyzing {total_items_analyzed} items, none meet the criteria for reordering. All items appear to have adequate stock levels relative to their forecasted demand.",
                "summary": {
                    "total_analyzed": total_items_analyzed,
                    "items_with_stock": len([d for d in data if flt(d.get('current_stock', 0)) > 0]),
                    "items_with_demand": len([d for d in data if flt(d.get('predicted_demand', 0)) > 0]),
                    "items_below_reorder": len([d for d in data if flt(d.get('current_stock', 0)) <= flt(d.get('reorder_level', 0))])
                },
                "suggestions": [
                    "Review reorder levels - they might be set too low",
                    "Check if demand forecasting is working properly",
                    "Verify stock quantities are up to date",
                    "Consider adjusting AI confidence thresholds"
                ]
            }
        
        # Calculate totals
        total_amount = sum(item['amount'] for item in preview_items)
        items_count = len(preview_items)
        
        # Get supplier options for the preview
        supplier_summary = analyze_supplier_distribution(preview_items)
        
        return {
            "success": True,
            "title": "ðŸ›’ AI Purchase Order Preview",
            "items_count": items_count,
            "total_amount": round(total_amount, 2),
            "primary_supplier": supplier_summary.get('primary_supplier'),
            "supplier_distribution": supplier_summary.get('distribution', {}),
            "items": preview_items,
            "validation_passed": True,
            "analysis_summary": {
                "total_items_analyzed": total_items_analyzed,
                "items_needing_reorder": items_count,
                "critical_items": len([i for i in preview_items if i['urgency_score'] > 80]),
                "high_priority_items": len([i for i in preview_items if i['urgency_score'] > 60]),
                "total_estimated_cost": round(total_amount, 2),
                "average_urgency": round(sum(i['urgency_score'] for i in preview_items) / max(items_count, 1), 1)
            },
            "insights": [
                f"ðŸ“¦ {items_count} out of {total_items_analyzed} items need reordering",
                f"ðŸ’° Total estimated cost: â‚¹{total_amount:,.2f}",
                f"ðŸš¨ {len([i for i in preview_items if i['urgency_score'] > 80])} critical items need immediate attention",
                f"ðŸ“Š Average urgency score: {sum(i['urgency_score'] for i in preview_items) / max(items_count, 1):.1f}%",
                f"ðŸª Primary supplier: {supplier_summary.get('primary_supplier', 'Multiple suppliers')}",
                "ðŸ¤– AI has optimized quantities and supplier selection based on historical data"
            ],
            "supplier_options": get_all_supplier_options(),
            "recommendation": f"Purchase Order preview ready for {items_count} items worth â‚¹{total_amount:,.2f}. Review quantities and suppliers before creating the order."
        }
        
    except Exception as e:
        frappe.log_error(f"AI purchase order preview failed: {str(e)}")
        return {
            "success": False,
            "error": f"Failed to generate purchase order preview: {str(e)}",
            "technical_details": "Check system logs for detailed error information"
        }

@frappe.whitelist()
def create_ai_purchase_order_from_preview(items_data=None, preview_data=None):
    """ðŸ›’ Create actual Purchase Order from enhanced preview data with supplier selection"""
    try:
        if isinstance(items_data, str):
            items_data = json.loads(items_data)
        if isinstance(preview_data, str):
            preview_data = json.loads(preview_data)
            
        if not items_data:
            return {"success": False, "error": "No items data provided for purchase order creation"}
        
        frappe.log_error(f"Creating PO from preview with {len(items_data)} items")
        
        # Group items by supplier for multiple POs if needed
        supplier_groups = group_items_by_supplier(items_data)
        
        created_pos = []
        total_amount = 0
        total_items = 0
        
        for supplier, supplier_items in supplier_groups.items():
            try:
                # Create Purchase Order for this supplier
                po_result = create_supplier_purchase_order(supplier, supplier_items)
                
                if po_result.get('success'):
                    created_pos.append(po_result)
                    total_amount += po_result.get('total_amount', 0)
                    total_items += po_result.get('items_count', 0)
                else:
                    frappe.log_error(f"Failed to create PO for supplier {supplier}: {po_result.get('error')}")
            
            except Exception as supplier_error:
                frappe.log_error(f"Error creating PO for supplier {supplier}: {str(supplier_error)}")
                continue
        
        if not created_pos:
            return {"success": False, "error": "Failed to create any purchase orders"}
        
        # Return success response
        if len(created_pos) == 1:
            # Single PO created
            po_result = created_pos[0]
            return {
                "success": True,
                "title": "âœ… AI Purchase Order Created Successfully",
                "po_number": po_result['po_number'],
                "supplier": po_result['supplier'],
                "total_amount": round(total_amount, 2),
                "items_count": total_items,
                "items": po_result.get('items', []),
                "po_link": po_result.get('po_link'),
                "next_steps": [
                    f"ðŸ“‹ Review Purchase Order: {po_result['po_number']}",
                    "âœ… Verify supplier information and rates",
                    "ðŸ“ž Contact supplier for confirmation", 
                    "ðŸ’° Check budget approval if required",
                    "ðŸ“… Confirm delivery schedule",
                    "ðŸšš Submit and process the order"
                ],
                "insights": [
                    f"ðŸ“„ Purchase Order: {po_result['po_number']}",
                    f"ðŸ’° Total Value: â‚¹{total_amount:,.2f}",
                    f"ðŸ“¦ Items: {total_items}",
                    f"ðŸª Supplier: {po_result['supplier']}"
                ]
            }
        else:
            # Multiple POs created
            po_numbers = [po['po_number'] for po in created_pos]
            return {
                "success": True,
                "title": "âœ… Multiple AI Purchase Orders Created",
                "po_numbers": po_numbers,
                "total_pos": len(created_pos),
                "total_amount": round(total_amount, 2),
                "items_count": total_items,
                "purchase_orders": created_pos,
                "next_steps": [
                    f"ðŸ“‹ Review {len(created_pos)} Purchase Orders: {', '.join(po_numbers)}",
                    "âœ… Verify supplier information for each PO",
                    "ðŸ“ž Contact suppliers for confirmation", 
                    "ðŸ’° Check budget approval if required",
                    "ðŸ“… Confirm delivery schedules",
                    "ðŸšš Submit and process the orders"
                ],
                "insights": [
                    f"ðŸ“„ Purchase Orders: {', '.join(po_numbers)}",
                    f"ðŸ’° Total Value: â‚¹{total_amount:,.2f}",
                    f"ðŸ“¦ Total Items: {total_items}",
                    f"ðŸª Suppliers: {len(created_pos)} different suppliers"
                ]
            }
        
    except Exception as e:
        frappe.log_error(f"Purchase order creation from preview failed: {str(e)}")
        return {
            "success": False,
            "error": f"Failed to create purchase order: {str(e)}"
        }

def group_items_by_supplier(items_data):
    """Group items by their selected supplier"""
    supplier_groups = {}
    
    for item in items_data:
        # Get supplier from preview selection or fallback to AI recommendation
        supplier = item.get('selected_supplier') or item.get('ai_supplier') or 'AI Default Supplier'
        
        if supplier not in supplier_groups:
            supplier_groups[supplier] = []
        
        supplier_groups[supplier].append(item)
    
    return supplier_groups

def create_supplier_purchase_order(supplier_name, items):
    """Create a Purchase Order for a specific supplier"""
    try:
        # Ensure supplier exists
        if not frappe.db.exists("Supplier", supplier_name):
            supplier_name = ensure_default_supplier()
        
        # Create the Purchase Order document
        po_doc = frappe.new_doc("Purchase Order")
        po_doc.supplier = supplier_name
        po_doc.company = frappe.defaults.get_user_default("Company") or frappe.db.get_single_value("Global Defaults", "default_company") or "AI Inventory"
        po_doc.transaction_date = frappe.utils.nowdate()
        po_doc.schedule_date = frappe.utils.add_days(frappe.utils.nowdate(), 7)
        
        # Enhanced remarks with AI context
        po_doc.remarks = f"This Purchase Order was automatically generated by AI Analytics for supplier {supplier_name}. Items selected based on stock analysis, demand forecasting, and supplier optimization."
        
        total_amount = 0
        po_items_details = []
        
        for item in items:
            try:
                item_code = item.get('item_code')
                if not item_code or not frappe.db.exists("Item", item_code):
                    continue
                
                # Get quantities and rates from preview
                order_qty = max(int(item.get('qty', item.get('suggested_qty', 10))), 1)
                rate = flt(item.get('rate', 100.0))
                
                # Get item details
                item_doc = frappe.get_doc("Item", item_code)
                stock_uom = item_doc.stock_uom or "Nos"
                
                # Get default warehouse
                default_warehouse = frappe.db.get_single_value("Stock Settings", "default_warehouse")
                if not default_warehouse:
                    warehouse_list = frappe.db.sql("SELECT name FROM tabWarehouse LIMIT 1", as_dict=True)
                    default_warehouse = warehouse_list[0].name if warehouse_list else "Main Warehouse"
                
                # Add item to Purchase Order
                po_item = po_doc.append("items", {
                    "item_code": item_code,
                    "item_name": item_doc.item_name,
                    "description": item_doc.description or item_doc.item_name,
                    "qty": order_qty,
                    "rate": rate,
                    "amount": order_qty * rate,
                    "uom": stock_uom,
                    "schedule_date": po_doc.schedule_date,
                    "warehouse": default_warehouse
                })
                
                total_amount += order_qty * rate
                
                po_items_details.append({
                    'item_code': item_code,
                    'item_name': item_doc.item_name,
                    'qty': order_qty,
                    'rate': rate,
                    'amount': order_qty * rate,
                    'urgency_score': item.get('urgency_score', 50),
                    'current_stock': item.get('current_stock', 0),
                    'supplier': supplier_name
                })
                
            except Exception as item_error:
                frappe.log_error(f"Failed to process item {item.get('item_code')}: {str(item_error)}")
                continue
        
        if not po_doc.items:
            return {"success": False, "error": f"No valid items found for supplier {supplier_name}"}
        
        # Save the document
        try:
            po_doc.insert()
            frappe.db.commit()
        except Exception as save_error:
            frappe.log_error(f"Purchase Order save failed for {supplier_name}: {str(save_error)}")
            return {"success": False, "error": f"Failed to save Purchase Order: {str(save_error)}"}
        
        return {
            "success": True,
            "po_number": po_doc.name,
            "supplier": po_doc.supplier,
            "total_amount": round(total_amount, 2),
            "items_count": len(po_doc.items),
            "items": po_items_details,
            "po_link": f"/app/purchase-order/{po_doc.name}"
        }
        
    except Exception as e:
        frappe.log_error(f"Failed to create PO for supplier {supplier_name}: {str(e)}")
        return {"success": False, "error": f"Failed to create purchase order for {supplier_name}: {str(e)}"}

def create_sample_po_items():
    """Create sample items for purchase order when no data is available"""
    try:
        # Get any existing items from the database
        items = frappe.db.sql("""
            SELECT name as item_code, item_name
            FROM tabItem 
            WHERE disabled = 0 
            LIMIT 5
        """, as_dict=True)
        
        sample_items = []
        for item in items:
            sample_items.append({
                'item_code': item.item_code,
                'item_name': item.get('item_name', item.item_code),
                'current_stock': 5,
                'reorder_level': 20,
                'predicted_demand': 25,
                'suggested_qty': 30,
                'urgency_score': 75,
                'stock_status': 'Below Reorder Level'
            })
        
        # If no items found, create generic sample data
        if not sample_items:
            sample_items = [
                {
                    'item_code': 'SAMPLE-001',
                    'item_name': 'Sample Item 1',
                    'current_stock': 5,
                    'reorder_level': 20,
                    'predicted_demand': 25,
                    'suggested_qty': 30,
                    'urgency_score': 80,
                    'stock_status': 'Critical'
                },
                {
                    'item_code': 'SAMPLE-002', 
                    'item_name': 'Sample Item 2',
                    'current_stock': 8,
                    'reorder_level': 15,
                    'predicted_demand': 20,
                    'suggested_qty': 25,
                    'urgency_score': 70,
                    'stock_status': 'Below Reorder Level'
                }
            ]
        
        return sample_items
        
    except Exception as e:
        frappe.log_error(f"Failed to create sample PO items: {str(e)}")
        return []

@frappe.whitelist()
def perform_quick_reorder_analysis(filters=None):
    """ðŸ“¦ Quick Reorder Analysis - Analyze reorder requirements with ML insights"""
    try:
        # Get data using existing function
        data = get_consolidated_predictive_data(filters or {})
        
        reorder_items = []
        critical_items = []
        total_value = 0
        
        for row in data:
            current_stock = flt(row.get('current_stock', 0))
            reorder_level = flt(row.get('reorder_level', 0))
            predicted_demand = flt(row.get('predicted_demand', 0))
            safety_stock = flt(row.get('safety_stock', 0))
            
            # Calculate reorder urgency
            urgency_score = 0
            if current_stock <= reorder_level:
                urgency_score += 40
            if current_stock <= safety_stock:
                urgency_score += 30
            if predicted_demand > current_stock:
                urgency_score += 20
            
            # Stock status analysis
            stock_status = "Normal"
            if current_stock == 0:
                stock_status = "Out of Stock"
                urgency_score += 30
            elif current_stock <= reorder_level:
                stock_status = "Below Reorder Level"
                urgency_score += 20
            elif current_stock <= safety_stock:
                stock_status = "Below Safety Stock"
                urgency_score += 15
            
            if urgency_score > 30:  # Needs reorder
                suggested_qty = max(predicted_demand - current_stock, reorder_level - current_stock, 0)
                if suggested_qty > 0:
                    item_value = suggested_qty * flt(row.get('valuation_rate', 100))
                    total_value += item_value
                    
                    reorder_item = {
                        'item_code': row.get('item_code'),
                        'item_name': row.get('item_name'),
                        'current_stock': current_stock,
                        'reorder_level': reorder_level,
                        'suggested_qty': round(suggested_qty, 2),
                        'urgency_score': urgency_score,
                        'stock_status': stock_status,
                        'estimated_value': round(item_value, 2),
                        'predicted_demand': predicted_demand,
                        'days_to_stockout': max(1, current_stock / max(predicted_demand / 30, 1))
                    }
                    
                    if urgency_score >= 70:
                        critical_items.append(reorder_item)
                    else:
                        reorder_items.append(reorder_item)
        
        # Sort by urgency
        critical_items.sort(key=lambda x: -x['urgency_score'])
        reorder_items.sort(key=lambda x: -x['urgency_score'])
        
        return {
            "success": True,
            "title": "ðŸ“¦ Quick Reorder Analysis",
            "summary": f"Found {len(critical_items)} critical and {len(reorder_items)} standard reorder requirements",
            "critical_items": critical_items[:10],  # Top 10 critical
            "reorder_items": reorder_items[:15],   # Top 15 standard
            "total_estimated_value": round(total_value, 2),
            "next_steps": [
                "Review critical items immediately",
                "Verify supplier availability",
                "Check budget allocation",
                "Create purchase orders",
                "Monitor delivery timelines"
            ],
            "insights": [
                f"ðŸ’° Total reorder value: â‚¹{total_value:,.2f}",
                f"ðŸš¨ {len(critical_items)} items need immediate attention",
                f"ðŸ“Š {len(reorder_items)} items require standard reordering",
                f"â±ï¸ Average days to stockout: {sum(item.get('days_to_stockout', 0) for item in critical_items + reorder_items) / max(len(critical_items + reorder_items), 1):.1f}"
            ]
        }
        
    except Exception as e:
        frappe.log_error(f"Quick reorder analysis failed: {str(e)}")
        return {"success": False, "error": str(e)}

@frappe.whitelist()
def identify_revenue_opportunities(filters=None):
    """ðŸ’° Revenue Opportunities - Identify potential revenue enhancement opportunities"""
    try:
        data = get_consolidated_predictive_data(filters or {})
        
        opportunities = []
        total_potential = 0
        
        for row in data:
            predicted_demand = flt(row.get('predicted_demand', 0))
            current_stock = flt(row.get('current_stock', 0))
            selling_price = flt(row.get('selling_price', 0))
            accuracy_score = flt(row.get('accuracy_score', 70))
            
            # Revenue opportunity calculations
            unmet_demand = max(0, predicted_demand - current_stock)
            potential_revenue = unmet_demand * selling_price
            
            # Market growth potential
            growth_rate = flt(row.get('growth_rate', 5))  # Default 5% growth
            market_expansion = predicted_demand * (growth_rate / 100) * selling_price
            
            # Price optimization opportunity
            margin_improvement = selling_price * 0.05  # 5% potential margin improvement
            price_optimization = current_stock * margin_improvement
            
            total_opportunity = potential_revenue + market_expansion + price_optimization
            
            if total_opportunity > 1000:  # Minimum threshold
                total_potential += total_opportunity
                
                opportunity = {
                    'item_code': row.get('item_code'),
                    'item_name': row.get('item_name'),
                    'current_stock': current_stock,
                    'predicted_demand': predicted_demand,
                    'unmet_demand': round(unmet_demand, 2),
                    'potential_revenue': round(potential_revenue, 2),
                    'market_expansion': round(market_expansion, 2),
                    'price_optimization': round(price_optimization, 2),
                    'total_opportunity': round(total_opportunity, 2),
                    'confidence': accuracy_score,
                    'priority': 'High' if total_opportunity > 50000 else 'Medium' if total_opportunity > 10000 else 'Low'
                }
                
                opportunities.append(opportunity)
        
        # Sort by opportunity value
        opportunities.sort(key=lambda x: -x['total_opportunity'])
        
        return {
            "success": True,
            "title": "ðŸ’° Revenue Opportunities",
            "summary": f"Identified {len(opportunities)} revenue opportunities worth â‚¹{total_potential:,.2f}",
            "opportunities": opportunities[:20],  # Top 20 opportunities
            "total_potential": round(total_potential, 2),
            "categories": {
                "unmet_demand": sum(op['potential_revenue'] for op in opportunities),
                "market_expansion": sum(op['market_expansion'] for op in opportunities),
                "price_optimization": sum(op['price_optimization'] for op in opportunities)
            },
            "next_steps": [
                "Increase stock for high-demand items",
                "Explore market expansion opportunities",
                "Review pricing strategies",
                "Analyze competitor positioning",
                "Develop marketing campaigns"
            ],
            "insights": [
                f"ðŸŽ¯ Top opportunity: â‚¹{opportunities[0]['total_opportunity']:,.2f}" if opportunities else "No major opportunities found",
                f"ðŸ“ˆ Market expansion potential: â‚¹{sum(op['market_expansion'] for op in opportunities):,.2f}",
                f"ðŸ’¡ Price optimization potential: â‚¹{sum(op['price_optimization'] for op in opportunities):,.2f}",
                f"â­ Average confidence: {sum(op['confidence'] for op in opportunities) / max(len(opportunities), 1):.1f}%"
            ]
        }
        
    except Exception as e:
        frappe.log_error(f"Revenue opportunity analysis failed: {str(e)}")
        return {"success": False, "error": str(e)}

@frappe.whitelist()
def assess_risk_factors(filters=None):
    """âš ï¸ Risk Assessment - Comprehensive risk analysis with mitigation strategies"""
    try:
        data = get_consolidated_predictive_data(filters or {})
        
        risks = []
        total_risk_value = 0
        
        for row in data:
            current_stock = flt(row.get('current_stock', 0))
            predicted_demand = flt(row.get('predicted_demand', 0))
            reorder_level = flt(row.get('reorder_level', 0))
            valuation_rate = flt(row.get('valuation_rate', 0))
            accuracy_score = flt(row.get('accuracy_score', 70))
            
            risk_factors = []
            risk_score = 0
            
            # Stock-out risk
            if current_stock <= 0:
                risk_factors.append("Complete stock-out")
                risk_score += 40
            elif current_stock <= reorder_level:
                risk_factors.append("Below reorder level")
                risk_score += 25
            
            # Demand volatility risk
            if accuracy_score < 60:
                risk_factors.append("High demand volatility")
                risk_score += 20
            
            # Overstocking risk
            if current_stock > predicted_demand * 3:
                risk_factors.append("Overstocking risk")
                risk_score += 15
            
            # Financial risk
            stock_value = current_stock * valuation_rate
            if stock_value > 100000:  # High value inventory
                risk_factors.append("High value inventory exposure")
                risk_score += 10
            
            # Obsolescence risk (placeholder - could be enhanced with aging data)
            if predicted_demand == 0 and current_stock > 0:
                risk_factors.append("Obsolescence risk")
                risk_score += 30
            
            if risk_score > 20:  # Threshold for significant risk
                total_risk_value += stock_value
                
                # Mitigation strategies
                mitigation = []
                if "stock-out" in str(risk_factors).lower():
                    mitigation.append("Immediate reorder")
                    mitigation.append("Emergency sourcing")
                if "overstocking" in str(risk_factors).lower():
                    mitigation.append("Promotional campaigns")
                    mitigation.append("Alternative channel sales")
                if "volatility" in str(risk_factors).lower():
                    mitigation.append("Improve forecasting models")
                    mitigation.append("Increase safety stock")
                if "obsolescence" in str(risk_factors).lower():
                    mitigation.append("Liquidation strategy")
                    mitigation.append("Product bundling")
                
                risk = {
                    'item_code': row.get('item_code'),
                    'item_name': row.get('item_name'),
                    'risk_score': risk_score,
                    'risk_level': 'Critical' if risk_score >= 60 else 'High' if risk_score >= 40 else 'Medium',
                    'risk_factors': risk_factors,
                    'current_stock': current_stock,
                    'stock_value': round(stock_value, 2),
                    'predicted_demand': predicted_demand,
                    'mitigation_strategies': mitigation,
                    'urgency': 'Immediate' if risk_score >= 60 else 'Soon' if risk_score >= 40 else 'Monitor'
                }
                
                risks.append(risk)
        
        # Sort by risk score
        risks.sort(key=lambda x: -x['risk_score'])
        
        # Risk summary
        critical_risks = [r for r in risks if r['risk_level'] == 'Critical']
        high_risks = [r for r in risks if r['risk_level'] == 'High']
        medium_risks = [r for r in risks if r['risk_level'] == 'Medium']
        
        return {
            "success": True,
            "title": "âš ï¸ Risk Assessment",
            "summary": f"Identified {len(critical_risks)} critical, {len(high_risks)} high, and {len(medium_risks)} medium risks",
            "risks": risks[:25],  # Top 25 risks
            "risk_distribution": {
                "critical": len(critical_risks),
                "high": len(high_risks), 
                "medium": len(medium_risks)
            },
            "total_risk_value": round(total_risk_value, 2),
            "next_steps": [
                "Address critical risks immediately",
                "Develop mitigation plans for high risks",
                "Monitor medium risks regularly",
                "Review and update risk thresholds",
                "Implement automated risk alerts"
            ],
            "insights": [
                f"ðŸš¨ {len(critical_risks)} items require immediate attention",
                f"ðŸ’° Total value at risk: â‚¹{total_risk_value:,.2f}",
                f"ðŸ“Š Average risk score: {sum(r['risk_score'] for r in risks) / max(len(risks), 1):.1f}",
                f"â° {len([r for r in risks if r['urgency'] == 'Immediate'])} items need immediate action"
            ]
        }
        
    except Exception as e:
        frappe.log_error(f"Risk assessment failed: {str(e)}")
        return {"success": False, "error": str(e)}

@frappe.whitelist()
def forecast_demand(filters=None):
    """ðŸ“ˆ Demand Forecasting - Advanced ML-powered demand predictions"""
    try:
        data = get_consolidated_predictive_data(filters or {})
        
        forecasts = []
        total_predicted_demand = 0
        
        for row in data:
            current_stock = flt(row.get('current_stock', 0))
            predicted_demand = flt(row.get('predicted_demand', 0))
            accuracy_score = flt(row.get('accuracy_score', 70))
            
            # Advanced forecasting calculations
            # 7-day forecast
            weekly_demand = predicted_demand / 4.33  # Convert monthly to weekly
            
            # 30-day forecast
            monthly_demand = predicted_demand
            
            # 90-day forecast
            quarterly_demand = predicted_demand * 3
            
            # Seasonal adjustment (placeholder - could be enhanced with historical data)
            seasonal_factor = 1.0  # Default no seasonal adjustment
            
            # Trend analysis
            growth_rate = flt(row.get('growth_rate', 0)) / 100
            trend_factor = 1 + growth_rate
            
            # Confidence intervals
            confidence_range = (100 - accuracy_score) / 100 * 0.3  # Max 30% variance
            lower_bound = monthly_demand * (1 - confidence_range)
            upper_bound = monthly_demand * (1 + confidence_range)
            
            # Stock adequacy analysis
            days_of_stock = (current_stock / max(weekly_demand / 7, 0.1)) if weekly_demand > 0 else 999
            stock_status = "Adequate"
            if days_of_stock < 7:
                stock_status = "Critical"
            elif days_of_stock < 14:
                stock_status = "Low"
            elif days_of_stock > 90:
                stock_status = "Excess"
            
            total_predicted_demand += monthly_demand
            
            forecast = {
                'item_code': row.get('item_code'),
                'item_name': row.get('item_name'),
                'current_stock': current_stock,
                'weekly_forecast': round(weekly_demand, 2),
                'monthly_forecast': round(monthly_demand, 2),
                'quarterly_forecast': round(quarterly_demand, 2),
                'confidence_score': accuracy_score,
                'lower_bound': round(lower_bound, 2),
                'upper_bound': round(upper_bound, 2),
                'days_of_stock': round(days_of_stock, 1),
                'stock_status': stock_status,
                'trend': 'Growing' if growth_rate > 0.05 else 'Declining' if growth_rate < -0.05 else 'Stable',
                'seasonal_factor': seasonal_factor,
                'recommended_action': 'Reorder' if days_of_stock < 14 else 'Monitor' if days_of_stock < 30 else 'Reduce' if days_of_stock > 90 else 'Maintain'
            }
            
            forecasts.append(forecast)
        
        # Sort by forecasted demand
        forecasts.sort(key=lambda x: -x['monthly_forecast'])
        
        # Summary statistics
        high_demand = [f for f in forecasts if f['monthly_forecast'] > 100]
        growing_items = [f for f in forecasts if f['trend'] == 'Growing']
        critical_stock = [f for f in forecasts if f['stock_status'] == 'Critical']
        
        return {
            "success": True,
            "title": "ðŸ“ˆ Demand Forecasting",
            "summary": f"Generated forecasts for {len(forecasts)} items with total monthly demand of {total_predicted_demand:,.0f} units",
            "forecasts": forecasts[:30],  # Top 30 forecasts
            "totals": {
                "weekly_total": sum(f['weekly_forecast'] for f in forecasts),
                "monthly_total": sum(f['monthly_forecast'] for f in forecasts),
                "quarterly_total": sum(f['quarterly_forecast'] for f in forecasts)
            },
            "statistics": {
                "high_demand_items": len(high_demand),
                "growing_items": len(growing_items),
                "critical_stock_items": len(critical_stock),
                "average_confidence": sum(f['confidence_score'] for f in forecasts) / max(len(forecasts), 1)
            },
            "next_steps": [
                "Review high-demand forecasts",
                "Address critical stock situations",
                "Monitor growing trend items",
                "Update safety stock levels",
                "Validate forecast accuracy"
            ],
            "insights": [
                f"ðŸ“Š {len(high_demand)} items have high monthly demand (>100 units)",
                f"ðŸ“ˆ {len(growing_items)} items show growing trends",
                f"ðŸš¨ {len(critical_stock)} items have critical stock levels",
                f"ðŸŽ¯ Average forecast confidence: {sum(f['confidence_score'] for f in forecasts) / max(len(forecasts), 1):.1f}%"
            ]
        }
        
    except Exception as e:
        frappe.log_error(f"Demand forecasting failed: {str(e)}")
        return {"success": False, "error": str(e)}

# Wrapper functions for JavaScript compatibility
@frappe.whitelist()
def perform_quick_reorder_analysis(filters=None):
    """ðŸ“¦ Quick Reorder Analysis - Wrapper for JS compatibility"""
    try:
        result = quick_reorder_analysis(filters)
        
        # Ensure all fields are properly formatted for frontend
        if result.get('success'):
            # Convert any complex objects to simple displayable format
            items = result.get('items', [])
            if items:
                # Ensure items are simple objects with string/number values only
                formatted_items = []
                for item in items:
                    formatted_item = {
                        'item_code': str(item.get('item_code', 'N/A')),
                        'item_name': str(item.get('item_name', 'N/A')),
                        'current_stock': float(item.get('current_stock', 0)),
                        'urgency_score': float(item.get('urgency_score', 0)),
                        'action_required': str(item.get('action_required', 'Review required')),
                        'status': str(item.get('status', 'Urgent'))
                    }
                    formatted_items.append(formatted_item)
                result['items'] = formatted_items
        
        # Ensure all result fields are JSON-serializable
        return {
            'success': result.get('success', False),
            'title': str(result.get('title', 'Quick Reorder Analysis')),
            'total_items': int(result.get('total_items', 0)),
            'critical_items': int(result.get('critical_items', 0)),
            'items': result.get('items', []),
            'recommendation': str(result.get('recommendation', 'No recommendations available'))
        }
        
    except Exception as e:
        frappe.log_error(f"Perform quick reorder analysis failed: {str(e)}")
        return {"success": False, "error": str(e)}

@frappe.whitelist()
def identify_revenue_opportunities(filters=None):
    """ðŸ’° Revenue Opportunities - Wrapper for JS compatibility"""
    try:
        result = revenue_opportunities(filters)
        
        # Ensure all fields are properly formatted for frontend
        if result.get('success'):
            items = result.get('items', [])
            if items:
                formatted_items = []
                for item in items:
                    formatted_item = {
                        'item_code': str(item.get('item_code', 'N/A')),
                        'item_name': str(item.get('item_name', 'N/A')),
                        'revenue_potential': float(item.get('revenue_potential', 0)),
                        'opportunity_score': float(item.get('opportunity_score', 0)),
                        'action_required': str(item.get('action_required', 'Review required')),
                        'status': str(item.get('status', 'Opportunity'))
                    }
                    formatted_items.append(formatted_item)
                result['items'] = formatted_items
        
        return {
            'success': result.get('success', False),
            'title': str(result.get('title', 'Revenue Opportunities')),
            'total_opportunities': int(result.get('total_opportunities', 0)),
            'total_revenue_potential': float(result.get('total_revenue_potential', 0)),
            'items': result.get('items', []),
            'recommendation': str(result.get('recommendation', 'No opportunities identified'))
        }
        
    except Exception as e:
        frappe.log_error(f"Identify revenue opportunities failed: {str(e)}")
        return {"success": False, "error": str(e)}

@frappe.whitelist()
def assess_risk_factors(filters=None):
    """âš ï¸ Risk Assessment - Wrapper for JS compatibility"""
    try:
        result = risk_assessment(filters)
        
        # Ensure all fields are properly formatted for frontend
        if result.get('success'):
            items = result.get('items', [])
            if items:
                formatted_items = []
                for item in items:
                    formatted_item = {
                        'item_code': str(item.get('item_code', 'N/A')),
                        'item_name': str(item.get('item_name', 'N/A')),
                        'risk_score': float(item.get('risk_score', 0)),
                        'current_stock': float(item.get('current_stock', 0)),
                        'action_required': str(item.get('action_required', 'Review required')),
                        'status': str(item.get('status', 'Risk'))
                    }
                    formatted_items.append(formatted_item)
                result['items'] = formatted_items
        
        return {
            'success': result.get('success', False),
            'title': str(result.get('title', 'Risk Assessment')),
            'high_risk_count': int(result.get('high_risk_count', 0)),
            'total_at_risk': int(result.get('total_at_risk', 0)),
            'items': result.get('items', []),
            'recommendation': str(result.get('recommendation', 'No risks identified'))
        }
        
    except Exception as e:
        frappe.log_error(f"Assess risk factors failed: {str(e)}")
        return {"success": False, "error": str(e)}

@frappe.whitelist()
def forecast_demand(filters=None):
    """ðŸ“ˆ Demand Forecasting - Wrapper for JS compatibility"""
    try:
        result = demand_forecasting(filters)
        
        # Ensure all fields are properly formatted for frontend
        if result.get('success'):
            items = result.get('items', [])
            if items:
                formatted_items = []
                for item in items:
                    formatted_item = {
                        'item_code': str(item.get('item_code', 'N/A')),
                        'item_name': str(item.get('item_name', 'N/A')),
                        'predicted_demand': float(item.get('predicted_demand', 0)),
                        'trend_direction': str(item.get('trend_direction', 'Stable')),
                        'action_required': str(item.get('action_required', 'Review required')),
                        'status': str(item.get('status', 'Forecast'))
                    }
                    formatted_items.append(formatted_item)
                result['items'] = formatted_items
        
        return {
            'success': result.get('success', False),
            'title': str(result.get('title', 'Demand Forecasting')),
            'growing_items': int(result.get('growing_items', 0)),
            'declining_items': int(result.get('declining_items', 0)),
            'items': result.get('items', []),
            'recommendation': str(result.get('recommendation', 'No forecast available'))
        }
        
    except Exception as e:
        frappe.log_error(f"Forecast demand failed: {str(e)}")
        return {"success": False, "error": str(e)}
